[{"title":"web-前端开发html","date":"2018-11-01T07:47:08.000Z","path":"2018/11/01/web-前端开发之HTML/","text":"&emsp;&emsp;HTML是英文Hyper Text Mark-up Language(超文本标记语言)的缩写，是一种制作万维网页面标准语言（标记）。通俗的讲就是相当于定义统一的一套规则，大家都来遵守他，这样就可以让浏览器根据标记语言的规则去解释它。浏览器负责将标签翻译成用户“看得懂”的格式，呈现给用户！ 简单HTML实例 4、编写Html文件 - doctype对应关系 - html标签，标签内部可以写属性 ====&gt; 只能有一个 - 注释： &lt;!-- 注释的内容 --&gt; 5、标签分类 - 自闭合标签 &lt;meta charset=&quot;UTF-8&quot;&gt; - 主动闭合标签 &lt;title&gt;老男孩&lt;/title&gt; 6、head标签 - &lt;meta -&gt; 编码，跳转，刷新，关键字，描述，IE兼容 &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=IE9;IE=IE8;&quot; /&gt; - title标签 - &lt;link /&gt; 定义文档与外部资源的关系 - &lt;style /&gt; 定义HTML文档样式信息 - &lt;script&gt; 定义客户端脚本，比如 JavaScript","tags":[{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"}]},{"title":"python-RabbitMQ 安装、基本示例、轮询机制","date":"2018-10-31T09:03:44.000Z","path":"2018/10/31/python-RabbitMQ 安装、基本示例、轮询机制/","text":"&emsp;&emsp;MQ全称为Message Queue, 是一种分布式应用程序的的通信方法，它是消费-生产者模型的一个典型的代表，producer往消息队列中不断写入消息，而另一端consumer则可以读取或者订阅队列中的消息。RabbitMQ是MQ产品的典型代表，是一款基于AMQP协议可复用的企业消息系统。业务上，可以实现服务提供者和消费者之间的数据解耦，提供高可用性的消息传输机制，在实际生产中应用相当广泛。本文意在介绍Rabbitmq的基本原理，以及在python下的各种应用。 python中的queue概念： 线程queue：只是用于多个线程之间，进行数据同步交互的。 进程queue：只是用户父进程与子进程进行交互，或者属于同一父进程下的多个子进程进行交互。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"RabbirMQ-win10环境下的安装","date":"2018-10-31T06:01:52.000Z","path":"2018/10/31/RabbirMQ-win10环境下的安装/","text":"链接 各种语言 各个独立的进程之间如果需要通信或者两台机器之间通信,需要RabbitMQ socket通信 json序列化 中间商通信(两个socket) 如果自己写socket,就要考虑粘包等 使用成熟的中间商 RabbitMQ是一个进程,里面可以维护很多的队列 如果没有处理完服务器宕机,消息在内存中会丢失,需要做持久化生产者和消费者都要写队列会还存在,但是数据会被丢失 这样队列中的数据也会持续化,在生产者加 公平分发(消费者加): channel.basic_qos(prefetch_count=1) # 在消息消费之前加上消息处理配置 生产者:消费者:","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"工具-ShareX+七牛云实现私有图床","date":"2018-10-29T01:33:42.000Z","path":"2018/10/29/工具-ShareX+七牛云实现私有图床/","text":"&emsp;&emsp;所谓图床，就是专门用来存放图片，同时允许你把图片对外连接的网上空间，通过访问链接就能直接查看或者分享图片，特别是个人博客的图片存储需要一个方便高效的私有图床，今天介绍一个通过ShareX+七牛云实现私有图床的方法。 什么是七牛云&emsp;&emsp;七牛云是国内一家领先的云存储公司，可以利用七牛云存储对象存储图片并生成外链。官网地址，注册后会赠送10G的免费空间. 什么是ShareX&emsp;&emsp;截图，这种再寻常不过的事情。有着很多的软件供我们选择，从常用的QQ到使用Snipaste。不光截图的方式多种多样，从处理截图，到上传截图到网络，都有软件能为你服务。但是，从截图，到处理截图，再到上传截图，至少需要用到两个软件。但是一个ShareX就能全部搞定。 用ShareX+qiniu一键截图上传配置1. sharex下载&emsp;&emsp;安装后打开如图 2. 设置图片上传&emsp;&emsp;打开 shareX -&gt; 目的地 -&gt; 目的地设置 -&gt; 自定义上传（最底下） 上传者：填入 qiniu，点击添加 请求 URL：进入自己的「对象存储」-&gt; 空间设置 -&gt; 存储区域，查看自己所在地区。根据 存储区域 - 七牛开发者中心 选择自己的地址，我是华东，填入 up.qiniup.com URL（右侧靠下）:自己的外链默认域名 + $json:key$ -&gt; xxxxx.bkt.clouddn.com/$json:key$ 上图中我的默认域名修改成了自己的默认域名qiniu.rearib.top 3. 重点：生成 token下载生成工具下载生成工具后执行： qiniutoken.exe -ak=[AccessKey] -sk=[SecretKey] -bk=[bucket] AccessKey和SecretKey登录七牛云-个人面板-秘钥管理-AK|SK bucket是存储空间名字 参数 &emsp;&emsp;在「参数」下有两个输入空框 左框 右框 token 上部生成的 token key %yy%d%h%mi%s.png file $input$ key 为上传时用的文件名，%yy%d%h%mi%s.png 是指年月日小时分钟秒，如 20180213165812.png 4.测试&emsp;&emsp;都配置完后，点击左侧「图片上传」-「测试」，若测试结果返回一个正常的连接地址那就是配置成功了。&emsp;&emsp;设置上传地址：sharex -&gt; 目的地 -&gt; 图片上传 -&gt; 自定义图像上传 &emsp;&emsp;截图后的动作 -&gt; 上传图片 按下快捷键截图后会自动上传并把七牛云返回的外链放到剪切板，成功后会有提示音并显示状态.打开浏览器粘贴 参考链接1、用 ShareX qiniu 一键截图上传 2、ShareX使用七牛文件上传 3、ShaseX","tags":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/tags/工具/"}]},{"title":"python-事件驱动和IO介绍","date":"2018-10-29T01:33:42.000Z","path":"2018/10/29/python-事件驱动和IO介绍/","text":"&emsp;&emsp;通常，我们写服务器处理模型的程序时，有以下几种模型： 每收到一个请求，创建一个新的进程，来处理该请求； 每收到一个请求，创建一个新的线程，来处理该请求； 每收到一个请求，放入一个事件列表，让主进程通过非阻塞I/O方式来处理请求 &emsp;&emsp;上面的几种方式，各有千秋： 第1中方法，由于创建新的进程的开销比较大，所以，会导致服务器性能比较差,但实现比较简单。 第2种方式，由于要涉及到线程的同步，有可能会面临死锁等问题。 第3种方式，在写应用程序代码时，逻辑比前面两种都复杂。&emsp;&emsp;综合考虑各方面因素，一般普遍认为第（3）种方式是大多数网络服务器采用的方式事件驱动模型&emsp;&emsp;在UI编程中，常常要对鼠标点击进行相应，首先如何获得鼠标点击呢？ 方式一：创建一个线程，该线程一直循环检测是否有鼠标点击，那么这个方式有以下几个缺点： CPU资源浪费，可能鼠标点击的频率非常小，但是扫描线程还是会一直循环检测，这会造成很多的CPU资源浪费；如果扫描鼠标点击的接口是阻塞的呢？ 如果是堵塞的，又会出现下面这样的问题，如果我们不但要扫描鼠标点击，还要扫描键盘是否按下，由于扫描鼠标时被堵塞了，那么可能永远不会去扫描键盘； 如果一个循环需要扫描的设备非常多，这又会引来响应时间的问题；所以，该方式是非常不好的。 方式二：就是事件驱动模型,目前大部分的UI编程都是事件驱动模型，如很多UI平台都会提供onClick()事件，这个事件就代表鼠标按下事件。事件驱动模型大体思路如下： 有一个事件（消息）队列； 鼠标按下时，往这个队列中增加一个点击事件（消息）； 有个循环，不断从队列取出事件，根据不同的事件，调用不同的函数，如onClick()、onKeyDown()等； 事件（消息）一般都各自保存各自的处理函数指针，这样，每个消息都有独立的处理函数； &emsp;&emsp;事件驱动编程是一种编程范式，这里程序的执行流由外部事件来决定。它的特点是包含一个事件循环，当外部事件发生时使用回调机制来触发相应的处理。另外两种常见的编程范式是（单线程）同步以及多线程编程。 &emsp;&emsp;让我们用例子来比较和对比一下单线程、多线程以及事件驱动编程模型。下图展示了随着时间的推移，这三种模式下程序所做的工作。这个程序有3个任务需要完成，每个任务都在等待I/O操作时阻塞自身。阻塞在I/O操作上所花费的时间已经用灰色框标示出来了。 &emsp;&emsp;在单线程同步模型中，任务按照顺序执行。如果某个任务因为I/O而阻塞，其他所有的任务都必须等待，直到它完成之后它们才能依次执行。这种明确的执行顺序和串行化处理的行为是很容易推断得出的。如果任务之间并没有互相依赖的关系，但仍然需要互相等待的话这就使得程序不必要的降低了运行速度。 &emsp;&emsp;在多线程版本中，这3个任务分别在独立的线程中执行。这些线程由操作系统来管理，在多处理器系统上可以并行处理，或者在单处理器系统上交错执行。这使得当某个线程阻塞在某个资源的同时其他线程得以继续执行。与完成类似功能的同步程序相比，这种方式更有效率，但程序员必须写代码来保护共享资源，防止其被多个线程同时访问。多线程程序更加难以推断，因为这类程序不得不通过线程同步机制如锁、可重入函数、线程局部存储或者其他机制来处理线程安全问题，如果实现不当就会导致出现微妙且令人痛不欲生的bug。 &emsp;&emsp;在事件驱动版本的程序中，3个任务交错执行，但仍然在一个单独的线程控制中。当处理I/O或者其他昂贵的操作时，注册一个回调到事件循环中，然后当I/O操作完成时继续执行。回调描述了该如何处理某个事件。事件循环轮询所有的事件，当事件到来时将它们分配给等待处理事件的回调函数。这种方式让程序尽可能的得以执行而不需要用到额外的线程。事件驱动型程序比多线程程序更容易推断出行为，因为程序员不需要关心线程安全问题。 &emsp;&emsp;当我们面对如下的环境时，事件驱动模型通常是一个好的选择： 程序中有许多任务，而且任务之间高度独立（因此它们不需要互相通信，或者等待彼此）,而且在等待事件到来时，某些任务会阻塞。 当应用程序需要在任务间共享可变的数据时，这也是一个不错的选择，因为这里不需要采用同步处理。 网络应用程序通常都有上述这些特点，这使得它们能够很好的契合事件驱动编程模型。 &emsp;&emsp;上面的事件驱动模型中，只要一遇到IO就注册一个事件，然后主程序就可以继续干其它的事情了，只到io处理完毕后，继续恢复之前中断的任务，这本质上是怎么实现的呢？ 阻塞IO,非阻塞IO,同步IO,异步IO介绍&emsp;&emsp;对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) &emsp;&emsp;正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以只提及剩下的四种IO Model。 1、概念说明 1.1、用户空间与内核空间 &emsp;&emsp;现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 1.2、进程切换 &emsp;&emsp;为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 &emsp;&emsp;从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 &emsp;&emsp;总而言之就是很耗资源，具体的可以参考这篇文章：进程切换 &emsp;&emsp;注：进程控制块（Processing Control Block），是操作系统核心中一种数据结构，主要表示进程状态。其作用是使一个在多道程序环境下不能独立运行的程序（含数据），成为一个能独立运行的基本单位或与其它进程并发执行的进程。或者说，OS是根据PCB来对并发执行的进程进行控制和管理的。 PCB通常是系统内存占用区中的一个连续存区，它存放着操作系统用于描述进程情况及控制进程运行所需的全部信息 1.3、进程阻塞 &emsp;&emsp;正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 1.4、文件描述符fd &emsp;&emsp;文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 &emsp;&emsp;文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 1.5、缓存I/O &emsp;&emsp;缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 &emsp;&emsp;缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 五种IO网络模式 阻塞 I/O（blocking IO） &emsp;&emsp;在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：&emsp;&emsp;当用户进程调用了recvfrom这个系统调用，kernel（内核）就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO） &emsp;&emsp;linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： &emsp;&emsp;当用户进程发出read操作时，如果kernel（内核）中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing） &emsp;&emsp;IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 &emsp;&emsp;当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel（内核）拷贝到用户进程。 &emsp;&emsp;这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 &emsp;&emsp;所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） &emsp;&emsp;在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 异步 I/O（asynchronous IO） &emsp;&emsp;Linux下的asynchronous IO其实用得很少。先看一下它的流程：&emsp;&emsp;用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel（内核）会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 总结： blocking和non-blocking的区别 &emsp;&emsp;调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel（内核）还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别 &emsp;&emsp;两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 &emsp;&emsp;有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 &emsp;&emsp;而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： IO多路复用（select、poll、epoll）介绍及select、epoll的实现&emsp;&emsp;IO多路复用中包括 select、pool、epoll，这些都属于同步，还不属于异步 1、select&emsp;&emsp;select最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 &emsp;&emsp;select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，事实上从现在看来，这也是它所剩不多的优点之一。 &emsp;&emsp;select的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制。 &emsp;&emsp;另外，select()所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长。同时，由于网络响应时间的延迟使得大量TCP连接处于非活跃状态，但调用select()会对所有socket进行一次线性扫描，所以这也浪费了一定的开销。 2、poll&emsp;&emsp;poll在1986年诞生于System V Release 3，它和select在本质上没有多大差别，但是poll没有最大文件描述符数量的限制。 &emsp;&emsp;poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。 &emsp;&emsp;另外，select()和poll()将就绪的文件描述符告诉进程后，如果进程没有对其进行IO操作，那么下次调用select()和poll()的时候将再次报告这些文件描述符，所以它们一般不会丢失就绪的消息，这种方式称为水平触发（Level Triggered）。 3、epoll&emsp;&emsp;直到Linux2.6才出现了由内核直接支持的实现方法，那就是epoll，它几乎具备了之前所说的一切优点，被公认为Linux2.6下性能最好的多路I/O就绪通知方法。 &emsp;&emsp;epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。 &emsp;&emsp;epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。 &emsp;&emsp;另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 select IO多路复用&emsp;&emsp;Python的select()方法直接调用操作系统的IO接口，它监控sockets,open files, and pipes(所有带fileno()方法的文件句柄)何时变成readable 和writeable, 或者通信错误，select()使得同时监控多个连接变的简单，并且这比写一个长循环来等待和监控多客户端连接要高效，因为select直接通过操作系统提供的C的网络接口进行操作，而不是通过Python的解释器。 &emsp;&emsp;select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样会造成效率的降低 继续看","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"python-协程","date":"2018-10-29T01:33:42.000Z","path":"2018/10/29/python-协程/","text":"&emsp;&emsp;协程，又称微线程。英文名Coroutine。一句话说明什么是协程：协程是一种用户态的轻量级线程。&emsp;&emsp;协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：&emsp;&emsp;协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。 协程的好处： 无需线程上下文切换的开销 无需原子操作锁定及同步的开销(协程是单线程,串行) “原子操作(atomic operation)是不需要synchronized”，所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序是不可以被打乱，或者切割掉只执行部分。视作整体是原子性的核心。 方便切换控制流，简化编程模型 高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。 协程的缺点： 无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。 进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序。 yield实现协程123456789101112131415161718192021222324import timedef consumer(name): print(&quot;---&gt;starting eating baozi...&quot;) while True: new_baozi = yield # yield设置生成器 print(&quot;[&#123;0&#125;] is eating baozi &#123;1&#125;&quot;.format(name, new_baozi)) def producer(): r = con.__next__() # 调用生成器开始执行 r = con2.__next__() n = 0 while n &lt; 5: time.sleep(1) print(&quot;producer is making baozi &#123;0&#125;&quot;.format(n)) con.send(n) # 唤醒生成器，并且向生成器传值 con2.send(n) n += 1 if __name__ == &apos;__main__&apos;: con = consumer(&quot;c1&quot;) # 创建一个生成器c1,但是不会开始执行 con2 = consumer(&quot;c2&quot;) # 创建一个生产器C2,但是不会开始执行 p = producer() send有两个作用？1.唤醒生产器2.给yield传一个值，就是yield接收到的这个值。这个说明yield在被唤醒的时候可以接收数据。 怎么实现我们的单线程实现并发的效果呢？&emsp;&emsp;遇到IO操作就切换，IO比较耗时，协程之所以能处理大并发，就是IO操作会挤掉大量的时间。没有IO操作的话，整个程序只有cpu在运算了，因为cpu很快，所以你感觉是在并发执行的。 IO操作完成了，程序什么时候切回去？&emsp;&emsp;IO操作一旦完成，我们就自动切回去。 IO是什么?&emsp;&emsp;Python中的io模块是用来处理各种类型的I/O操作流。主要有三种类型的I/O类型：文本I/O(Text I/O)，二进制I/O(Binary I/O)和原始I/O(Raw I/O)。它们都是通用类别，每一种都有不同的后备存储。属于这些类别中的任何一个的具体对象称为文件对象，其他常用的术语为流或者类文件对象。&emsp;&emsp;除了它的类别，每一种具体的流对象也具有各种功能：它仅仅允许读，或者仅仅允许写，或者既能读又能写。它也允许任意随机访问（向前或者向后寻找任何位置），或者仅仅顺序访问（例如在套接字或管道中）。&emsp;&emsp;所有的流对于提供给它们的数据的数据类型都很严格。例如，如果用一个二进制流的write（）方法写一个字符类型的数据，那么将会触发一个TypeError错误。用文本流的write()方法来写字节对象数据也是一样的，会触发该错误。手动实现切换IO&emsp;&emsp;Greenlet是python的一个C扩展，来源于Stackless python，旨在提供可自行调度的‘微线程’， 即协程。它可以使你在任意函数之间随意切换，而不需把这个函数先声明为generator12345678910111213141516from greenlet import greenlet def test1(): print(12) gr2.switch() # 切换到test2 print(34) gr2.switch() # 切换到test2 def test2(): print(56) gr1.switch() # 切换到test1 print(78) gr1 = greenlet(test1) # 启动一个协程gr2 = greenlet(test2)gr1.switch() # 切换到test1，这个switch不写的话，会无法输出打印 小结： cpu只认识线程，而不认识协程，协程是用户自己控制的，cpu根本都不知道它们的存在。 线程的上下文切换保存在cpu的寄存器中，但是协程拥有自己的寄存上下文和栈。 协程是串行的，无需锁。 虽然greenlet确实用着比generator（生成器）还简单了，但好像还没有解决一个问题，就是遇到IO操作，自动切换，对不对？协程遇IO操作自动切换&emsp;&emsp;接下来就说说如何遇到IO就自动切换切换，Gevent 是一个第三方库，可以轻松通过gevent实现并发同步或异步编程，在gevent中用到的主要模式是Greenlet, 它是以C扩展模块形式接入Python的轻量级协程。 Greenlet全部运行在主程序操作系统进程的内部，但它们被协作式地调度。12345678910111213141516171819202122import gevent def foo(): print(&quot;Running in foo&quot;) gevent.sleep(3) # 模仿io操作，一遇到io操作就切换 print(&quot;Explicit context switch to foo again&quot;) def bar(): print(&quot;Explicit context to bar&quot;) gevent.sleep(1) print(&quot;Implicit context switch back to bar&quot;) def fun3(): print(&quot;running fun3&quot;) gevent.sleep(0) # 虽然是0秒，但是会触发一次切换 print(&quot;running fun3 again&quot;) gevent.joinall([ gevent.spawn(foo), # 生成协程 gevent.spawn(bar), gevent.spawn(fun3)]) &emsp;&emsp;当foo遇到sleep(3)的时候，切自动切换到bar函数，执行遇到sleep(1)的时候自动切换到fun3函数，遇到sleep(0)又自动切换到foo。这个时候sleep(3)还没有执行完毕，又切换到bar的sleep(1)这边，发现又没有执行完毕，就有执行fun3这边，发现sleep(0)执行完毕，则继续执行，然后又切换到foo,发现sleep(3)又没有执行完毕，就切换到bar的sleep(1)这边，发现执行完了，有切回到foo这边，执行完毕。&emsp;&emsp;比如说你现在有50处IO，然后总共加起来串行的的话，要花100秒，但是50处IO最长的那个IO只花了5秒钟，那代表中你的这个程序就是协程最多5秒就执行完毕了。 符合下面四个条件才能称之为协程： 必须在只有一个单线程里实现并发 修改共享数据不需加锁 用户程序里自己保存多个控制流的上下文栈 一个协程遇到IO操作自动切换到其它协程 协程（gevent）并发爬网页&emsp;&emsp;上面例子gevent遇到io自动切换，现在就来实际演示协程爬虫的例子正常（串行）爬网页123456789101112131415161718192021from urllib import requestimport time def run(url): print(&quot;GET:&#123;0&#125;&quot;.format(url)) resp = request.urlopen(url) # request.urlopen()函数 用来打开网页 data = resp.read() # 读取爬到的数据 with open(&quot;url.html&quot;, &quot;wb&quot;) as f: f.write(data) print(&apos;&#123;0&#125; bytes received from &#123;1&#125;&apos;.format(len(data), url)) urls = [ &apos;http://www.163.com/&apos;, &apos;https://www.yahoo.com/&apos;, &apos;https://github.com/&apos;] time_start = time.time() # 开始时间for url in urls: run(url)print(&quot;同步cost&quot;, time.time() - time_start) # 程序执行消耗的时间 协程(gevent)爬虫(gevent并发执行)123456789101112131415161718192021222324from urllib import requestimport time,gevent def run(url): print(&quot;GET:&#123;0&#125;&quot;.format(url)) resp = request.urlopen(url) # request.urlopen()函数 用来打开网页 data = resp.read() # 读取爬到的数据 with open(&quot;url.html&quot;, &quot;wb&quot;) as f: f.write(data) print(&apos;&#123;0&#125; bytes received from &#123;1&#125;&apos;.format(len(data), url)) urls = [ &apos;http://www.163.com/&apos;, &apos;https://www.yahoo.com/&apos;, &apos;https://github.com/&apos;] time_start = time.time() # 开始时间gevent.joinall([ gevent.spawn(run,&apos;http://www.163.com/&apos;), # 生成协程 gevent.spawn(run,&apos;https://www.yahoo.com/&apos;), gevent.spawn(run,&apos;https://github.com/&apos;)])print(&quot;异步cost&quot;, time.time() - time_start) # 程序执行消耗的时间对比1、2爬网页的例子，发现执行耗费时间上并没有得到明显提升，并没有并发爬网页的神奇快感，其实主要是因为gevent现在检测不到urllib的IO操作。它都不知道urllib进行了IO操作，感受不到阻塞，它都不会进行切换，所以它就串行了。 打个补丁，告诉gevent,urllib正在进行IO操作通过导入monkey模块，来打这个补丁，原代码不变，就添加一行monkey.patch_all()即可。123456789101112131415161718192021222324252627from urllib import requestimport gevent,timefrom gevent import monkey # 导入monkey模块 monkey.patch_all() # 把当前程序的所有的IO操作给作上标记 def run(url): print(&quot;GET:&#123;0&#125;&quot;.format(url)) resp = request.urlopen(url) # request.urlopen()函数 用来打开网页 data = resp.read() # 读取爬到的数据 with open(&quot;url.html&quot;, &quot;wb&quot;) as f: f.write(data) print(&apos;&#123;0&#125; bytes received from &#123;1&#125;&apos;.format(len(data), url)) urls = [ &apos;http://www.163.com/&apos;, &apos;https://www.yahoo.com/&apos;, &apos;https://github.com/&apos;] time_start = time.time() # 开始时间gevent.joinall([ # 用gevent启动协程 gevent.spawn(run, &apos;http://www.163.com/&apos;), # 第二个值是传入参数，之前我们没有讲，因为前面没有传参 gevent.spawn(run, &apos;https://www.yahoo.com/&apos;), gevent.spawn(run, &apos;https://github.com/&apos;),])print(&quot;异步cost&quot;, time.time() - time_start) # 程序执行消耗的时间时间会受到网络状态的影响&emsp;&emsp;通过打补丁来检测urllib，它就把urllib里面所有涉及到的有可能进行IO操作的地方直接花在前面加一个标记，这个标记就相当于gevent.sleep()，所以把urllib变成一个一有阻塞，它就切换了 gevent实现单线程下的多socket并发server端1234567891011121314151617181920212223242526import sys,gevent,socket,timefrom gevent import socket,monkeymonkey.patch_all() def server(port): s = socket.socket() s.bind((&apos;0.0.0.0&apos;, port)) s.listen(500) while True: cli, addr = s.accept() gevent.spawn(handle_request, cli) #协程 def handle_request(conn): try: while True: data = conn.recv(1024) print(&quot;recv:&quot;, data) conn.send(data) if not data: conn.shutdown(socket.SHUT_WR) except Exception as ex: print(ex) finally: conn.close()if __name__ == &apos;__main__&apos;: server(8888) client端123456789101112import socket HOST = &apos;localhost&apos; # The remote hostPORT = 8888 # The same port as used by the servers = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((HOST, PORT))while True: msg = bytes(input(&quot;&gt;&gt;:&quot;),encoding=&quot;utf8&quot;) s.sendall(msg) data = s.recv(1024) print(&apos;Received&apos;, repr(data))s.close()","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"python-多进程","date":"2018-10-26T15:15:10.000Z","path":"2018/10/26/python-多进程/","text":"&emsp;&emsp;进程之间是相互独立的，进程没有GIL锁，而且不存在锁的概念，进程之间的数据式不能共享的，而线程是可以的。 多进程进程的定义&emsp;&emsp;用muliprocessing这个包中的Process来定义多进程，跟定义多线程类似12345678910111213141516from multiprocessing import Process # 导入进程模块import time def run(name): time.sleep(2) print(&quot;hello&quot;, name) if __name__ == &quot;__main__&quot;: p_obj_list = list() # 存放进程对象 for i in range(10): # 启动10个进程 p = Process(target=run, args=(&quot;QQ&#123;0&#125;&quot;.format(i),)) # 产生一个进程实例 p.start() # 启动进程 p_obj_list.append(p) for p in p_obj_list: p.join() # 等待进程结果 进程中加入线程123456789101112131415161718192021from multiprocessing import Processimport time,threading def thread_run(name): # 定义线程执行的方法 print(&quot;&#123;0&#125;:&#123;1&#125;&quot;.format(name, threading.get_ident())) # thread.get_ident ()返回当前线程的标识符，标识符是一个非零整数 def run(name): time.sleep(2) print(&quot;hello&quot;, name) t = threading.Thread(target=thread_run, args=(name,)) # 嵌入线程 t.start() # 执行线程 if __name__ == &quot;__main__&quot;: p_obj_list = list() for i in range(10): p = Process(target=run, args=(&quot;QQ&#123;0&#125;&quot;.format(i),)) p.start() p_obj_list.append(p) for p in p_obj_list: p.join() 父子进程每个子进程都是由一个父进程启动的，每个程序也是有一个父进程12345678910111213141516171819from multiprocessing import Processimport os def info(title): print(title) print(&apos;module name:&apos;, __name__) print(&apos;parent process:&apos;, os.getppid()) # 获得父进程ID print(&apos;process id:&apos;, os.getpid()) # 获得子进程ID print(&apos;\\n&apos;) def f(name): info(&apos;function f&apos;) print(&apos;hello&apos;, name) if __name__ == &apos;__main__&apos;: info(&apos;main process line&apos;) p = Process(target=f, args=(&apos;QQ&apos;,)) p.start() p.join() 进程间数据交互与共享&emsp;&emsp;知道不同进程之间内存是不共享的，要想实现两个进程间的通信需要用到multiprocessing库中的queue（队列）模块，这个multiprocessing库中的queue模块跟单纯的queue库是不一样的。进程导入前者（这里的queue是专门为进程之间的通信设计的）不出错，导入后者（这里的queue主要是线程间数据交互）出错。 线程访问queue1234567891011import queue,threadingdef f(q): q.put([66, None, &apos;hello word&apos;])if __name__ == &apos;__main__&apos;: q = queue.Queue() # 把这个q传给了子线程 p = threading.Thread(target=f, args=(q,)) # 子线程访问父线程的q p.start() print(q.get()) p.join() 进程访问queue123456789101112from multiprocessing import Processimport queuedef f(q): q.put([66, None, &apos;hello word&apos;])if __name__ == &apos;__main__&apos;: q = queue.Queue() # 把这个q传给了子线程 p = Process(target=f, args=(q,)) # 子线程访问父线程的q p.start() print(q.get()) p.join() 进程访问multiprocessing库中的Queue模块1234567891011from multiprocessing import Process,Queue def f(q): q.put([66, None, &apos;hello word&apos;]) if __name__ == &apos;__main__&apos;: q = Queue() # 把这个q传给了子线程 p = Process(target=f, args=(q,)) # 子线程访问父线程的q p.start() print(q.get()) p.join() &emsp;&emsp;父进程相当于克隆一个Q，把自己的Q克隆了一份交给子进程，子进程这个时候往Q里面放了一份数据，然后父进程又能实际的获取到。但是你克隆了一份是不是就和父进程没有关系了，为什么还能联系在一起呢？但是实际上：等于这两个Q里面的数据又把它序列化了，序列化到一个中间的地方，类似于翻译，然后反序列化给这个父进程这边来了，其实这两个Q就是通过pickle来序列化的，不是一个真正的Q。小结：两个线程之间可以修改一个数据，不加锁，可能就会出错。现在进程中的Queue，是实现了数据的传递，不是在修改同一份数据，只是实现一个进程的数据传给了另外一个进程。 Pipe()实现进程间的数据交互，manger实现数据共享&emsp;&emsp;上面的例子是通过进程中的Queue，来进行数据共享的，其实还有一种方式实现数据共享，那就是管道，pipe，以及数据共享manger。 Pipe()函数&emsp;&emsp;管道函数会返回由管道双方连接的一组连接对象，该管道默认是双向的(双向的)。1234567891011121314from multiprocessing import Process, Pipe def f(conn): conn.send([66, None, &apos;hello,word&apos;]) # 发送消息给父进程 conn.send([66, None, &apos;hello,word2&apos;]) # 发送消息给父进程 conn.close() if __name__ == &apos;__main__&apos;: parent_conn, child_conn = Pipe() # 管道生成返回两个实例，是双向的，这边把第1个作为父连接，第2个作为子连接。也可以，两者角色调换一下 p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) # 接收子进程的消息 print(parent_conn.recv()) # 接收子进程的消息 p.join()如果父进程在接收,但是子进程没有发,那么父进程就会一直等待下去 manger()&emsp;&emsp;manger可以完成数据间的共享。12345678910111213141516171819202122from multiprocessing import Process, Managerimport os def f(d, l): d[os.getpid()] = os.getpid() l.append(os.getpid()) print(l) if __name__ == &apos;__main__&apos;: with Manager() as manager: d = manager.dict() # 声明一个字典，这个字典是用manger声明的，不是用dict()声明的 # manger.dict()是用专门的语法生产一个可在多进程之间进行传递和共享的一个字典 l = manager.list(range(5)) # 同样声明一个列表 p_list = [] for i in range(10): p = Process(target=f, args=(d, l)) p.start() p_list.append(p) for res in p_list: res.join() print(d) print(l)线程修改同一份数据的时候需要加锁，进程修改数据呢：不用加锁，因为这个manger已经帮你加锁了，它就默认不允许两个进程同时修改一份数据。两个进程没有办法同时修改一份数据，进程之间是独立的，它自己也要加锁，因为它把自己的东西同时copy好几份，跟刚刚的那个Queue一样，copy10个字典最终合成一个字典 进程锁和进程池进程锁&emsp;&emsp;通过multiprocessing中的Lock模块来实现进程锁1234567891011from multiprocessing import Process,Lock # 导入进程锁 def f(l, i): l.acquire() # 加锁 print(&quot;hello word&quot;, i) l.release() # 释放锁 if __name__ == &quot;__main__&quot;: lock = Lock() # 定义锁 for num in range(10): Process(target=f, args=(lock, num,)).start() # 把锁传入进程中进程中不是相互独立的吗？为什么还要加锁：虽然每个进程都是独立运行的，但是问题来了，它们共享一块屏幕。这个锁存在的意义就是屏幕共享。如果进程1想着打印数据，而进程2想也想打印数据的情况，就有可能乱套了，然后通过这个锁来控制，去打印的时候，这个屏幕只有我独占，导致屏幕不会乱。 进程池apply和apply_sayncappley&emsp;&emsp;同步执行，也就是串行执行的1234567891011121314from multiprocessing import Pool # 导入进程池模块poolimport time,os def foo(i): time.sleep(2) print(&quot;in process&quot;, os.getpid()) # 打印进程号 if __name__ == &quot;__main__&quot;: pool = Pool(processes=5) # 设置进程池个数为5，也可以写成pool = Pool(5)，允许进程池同时放入5个进程，并且这5个进程交给cpu去运行 for i in range(10): pool.apply(func=foo, args=(i,)) # 同步执行挂起进程 print(&apos;end&apos;) pool.close() pool.join() # 进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。一个一个打印 apply_saync&emsp;&emsp;异步执行，也就是并行执行。1234567891011121314from multiprocessing import Pool # 导入进程池模块poolimport time,os def foo(i): time.sleep(2) print(&quot;in process&quot;, os.getpid()) # 打印进程号 if __name__ == &quot;__main__&quot;: pool = Pool(processes=5) # 设置进程池个数为5，也可以写成pool = Pool(5)，允许进程池同时放入5个进程，并且这5个进程交给cpu去运行 for i in range(10): pool.apply_async(func=foo, args=(i,)) # 采用异步方式执行foo函数 print(&apos;end&apos;) pool.close() pool.join() # 进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。 异步下回调函数&emsp;&emsp;程序执行完毕之后，再回调过来执行这个Bar函数。12345678910111213141516171819from multiprocessing import Process,Poolimport time,os def foo(i): time.sleep(2) print(&quot;in process&quot;, os.getpid()) # 打印子进程的进程号 return i def bar(arg): print(&apos;--&gt;exec done:&apos;, arg, os.getpid()) # 打印进程号 if __name__ == &quot;__main__&quot;: pool = Pool(processes=2) print(&quot;主进程&quot;, os.getpid()) # 主进程的进程号 for i in range(3): pool.apply_async(func=foo, args=(i,), callback=bar) # 执行回调函数callback=Bar,在主进程中执行 print(&apos;end&apos;) pool.close() pool.join() # 进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。五个五个打印回调函数在主进程执行,传入的参数来自子进程 回调函数说明fun=Foo干不完就不执行bar函数，等Foo执行完就去执行Bar 这个回调函数是主进程去调用的，而不是每个子进程去调用的。 回调函数的用处： 比如说你从各个机器上备份完毕，在回调函数中自动写一个脚本，说备份完毕 回调函数是主进程调用的原因？ 如果是子进程去调用这个回调函数，有多少个子进程就有多少个连接，如果是主进程的话，只需要一次长连接就可以了，这个效率就高了","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"python-队列与生产者消费者模式","date":"2018-10-26T01:47:08.000Z","path":"2018/10/26/python-队列与生产者消费者模式/","text":"&emsp;&emsp;并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度。1、为什么要使用生产者和消费者模式&emsp;&emsp;在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。2、什么是生产者消费者模式&emsp;&emsp;生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。 队列&emsp;&emsp;队列（Queue）:在多个线程之间安全的交换数据信息，队列在多线程编程中特别有用队列的好处： 提高双方的效率，你只需要把数据放到队列中，中间去干别的事情。 完成了程序的解耦性，两者关系依赖性没有不大。 队列的类型： lass queue.Queue(maxsize=0) 先进先出，后进后出12345678import queueq = queue.Queue() # 生成先入先出队列实例q.put(1) # 先放进1，再放入2q.put(2)print(q.get()) #输出1 class queue.LifoQueue(maxsize=0) 先进后出，后进先出12345678import queueq = queue.LifoQueue() # 生成先入先出队列实例q.put(1) # 先放进1，再放入2q.put(2)print(q.get()) #输出2 class queue.PriorityQueue(maxsize=0)优先级来取数据。存放数据的格式 : Queue.put((priority_number,data))，priority_number越小，优先级越高，data代表存入的值12345678910111213import queueq = queue.PriorityQueue()q.put((1, &quot;d1&quot;))q.put((-1, &quot;d2&quot;))q.put((6, &quot;d3&quot;))print(q.get())print(q.get())print(q.get()) #输出(-1, &apos;d2&apos;)(1, &apos;d1&apos;)(6, &apos;d3&apos;) maxsize代表这个队列最大能够put的长度，如果xsize &lt;= 0，则队列大小为无限大。 队列的内置方法 exception queue.Empty队列中的数据为空时，就会抛出这个异常。 12345678910import queueq = queue.Queue()q.get(block=False) #获取不到的时候#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 161, in get raise Emptyqueue.Empty exception queue.Full当队列中满了以后，再放数据的话，就会抛出此异常。 12345678910111213import queueq = queue.Queue(maxsize=1) q.put(1)q.put(1,block=False)#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 184, in put_nowait return self.put(item, block=False) File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 130, in put raise Fullqueue.Full Queue.qsize()查看队列的大小。 12345678import queueq = queue.Queue() q.put(20)q.put(21)print(q.qsize()) #查看队列的大小#输出2 Queue.empty()队列如果为空返回True，不为空返回False。 12345678910import queueq = queue.Queue() q.put(1)print(q.empty()) #查看队列是否为空q.get()print(q.empty()) #查看队列是否为空#输出FalseTrue Queue.full()队列如果满了，返回True，没有满返回False。 12345678910import queueq = queue.Queue(maxsize=1) q.put(1)print(q.full()) #查看队列是否满q.get()print(q.full()) #查看队列是否满#输出TrueFalse Queue.put(item,block=True,timeout=None)把数据插入队列中。block参数默认为true，timeout默认值是None。如果blcok为false的话，那么在put时候超过设定的maxsize的值，就会报full 异常。如果timeout设置值得话，说明put值得个数超过maxsize值，那么会在timeout几秒之后抛出full异常。 1234567891011import queueq = queue.Queue(maxsize=1) #是定队列的大小为1q.put(1)q.put(1,block=False) #block不会阻塞，会full异常#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 130, in put raise Fullqueue.Full 1234567891011import queueq = queue.Queue(maxsize=1) #是定队列的大小为1q.put(1)q.put(1,timeout=1) #超过1秒，则会报full异常#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 130, in put raise Fullqueue.Full Queue.put_nowait(item)等同于Queue.put(item,block=False)或者是Queue.put(item,False)。 123456789101112import queueq = queue.Queue(maxsize=1)q.put(1)q.put_nowait(1) #等同于q.put(1,block=False)#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 184, in put_nowait return self.put(item, block=False) File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 130, in put raise Fullqueue.Full Queue.get(block=True,timeout=None)移除并返回队列中的序列。参数block=true并且timeout=None。如果block=false的话，那么队列为空的情况下，就直接Empty异常。如果timeout有实际的值，这个时候队列为空，执行get的时候，则时隔多长时间则报出Empty的异常。 1234567891011import queueq = queue.Queue()q.put(1)q.get()q.get(block=False) #获取不到值，直接抛Empty异常#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 161, in get raise Emptyqueue.Empty 1234567891011import queueq = queue.Queue()q.put(1)q.get()q.get(timeout=1) #设置超时时间，抛出Empty异常#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 172, in get raise Emptyqueue.Empty Queue.get_nowait(item)等同于Queue.get(block=False)或者Queue.get(False)。 12345678910111213import queueq = queue.Queue()q.put(1)q.get()q.get_nowait() #等同于q.get(block=False)#输出Traceback (most recent call last): File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt; File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 192, in get_nowait return self.get(block=False) File &quot;D:\\Python\\Python35\\lib\\queue.py&quot;, line 161, in get raise Emptyqueue.Empty Queue.task_done()get()用于获取任务，task_done()则是用来告诉队列之前获取的任务已经处理完成 Queue.join()block(阻塞)直到queue（队列）被消费完毕,如果生产者生产10个包子，那么要等消费者把这个10个包子全部消费完毕，生产者才能继续往下执行。 task_done和jion的理解 生成者消费者模型例子生产者生产完毕，消费者再消费例子：1234567891011121314151617181920212223import threadingimport queue def producer(): for i in range(10): q.put(&quot;骨头 %s&quot; % i) print(&quot;开始等待所有的骨头被取走...&quot;) q.join() # 等待这个骨头队列被消费完毕 print(&quot;所有的骨头被取完了...&quot;)def consumer(n): while q.qsize() &gt; 0: print(&quot;%s 取到&quot; % n, q.get()) q.task_done() # 每去到一个骨头，便告知队列这个任务执行完了 q = queue.Queue() p = threading.Thread(target=producer,)p.start() c1 = consumer(&quot;QQ&quot;) 边生产边消费的模型例子1234567891011121314151617181920212223242526272829import time,randomimport queue,threadingq = queue.Queue() def producer(name): count = 0 while count &lt; 10: time.sleep(random.randrange(3)) q.put(count) # 在队列里放包子 print&apos;Producer %s has produced %s baozi..&apos; (% (name, count)) count += 1 def consumer(name): count = 0 while count &lt; 10: time.sleep(random.randrange(4)) if not q.empty(): # 如果还有包子 data = q.get() # 就继续获取保证 print(data) print(&apos;Consumer %s has eat %s baozi...&apos; % (name, data)) else: print(&quot;-----no baozi anymore----&quot;) count += 1 p1 = threading.Thread(target=producer, args=(&apos;A&apos;,))c1 = threading.Thread(target=consumer, args=(&apos;B&apos;,))p1.start()c1.start() 流程图: 生产者生产，消费者消费。 消费者每消费一次，都要去执行以下task_done()方法，来告诉消费者已经消费成功，相当于吃完饭，消费者应该给钱了。 消费者每消费一次，则队列中计数器会做减1操作。 当队列中的计数器为0的时候，则生产者不阻塞，继续执行，不为0的时候，则阻塞，直到消费者消费完毕为止。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"python-线程与进程","date":"2018-10-26T01:47:08.000Z","path":"2018/10/26/python-线程与进程/","text":"&emsp;&emsp;计算机所有的指令的操作都是有CPU来负责的，cpu是来负责运算的。OS(操作系统) 调度cpu的最小单位就是线程。&emsp;&emsp;进程：是以一个整体的形式暴露给操作系统管理，里面包含对各种资源的调用，内存的管理，网络接口的调用等等，是各种资源管理的集合&emsp;&emsp;线程：是操作系统的最小的调度单位，是一串指令的集合。 进程(Process）&emsp;&emsp;程序并不能单独运行，只有将程序装载到内存中，系统为它分配资源才能运行，而这种执行的程序就称之为进程。程序和进程的区别就在于：程序是指令的集合，它是进程运行的静态描述文本；进程是程序的一次执行活动，属于动态概念。&emsp;&emsp;在多道编程中，我们允许多个程序同时加载到内存中，在操作系统的调度下，可以实现并发地执行。这是这样的设计，大大提高了CPU的利用率。进程的出现让每个用户感觉到自己独享CPU，因此，进程就是为了在CPU上实现多道编程而提出的。 线程(Thead)&emsp;&emsp;线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 有了进程为什么还要线程?&emsp;&emsp;进程有很多优点，它提供了多道编程，让我们感觉我们每个人都拥有自己的CPU和其他资源，可以提高计算机的利用率。很多人就不理解了，既然进程这么优秀，为什么还要线程呢？其实，仔细观察就会发现进程还是有很多缺陷的，主要体现在两点上： 进程只能在一个时间干一件事，如果想同时干两件事或多件事，进程就无能为力了。 进程在执行的过程中如果阻塞，例如等待输入，整个进程就会挂起，即使进程中有些工作不依赖于输入的数据，也将无法执行。 &emsp;&emsp;例如，我们在使用qq聊天， qq做为一个独立进程如果同一时间只能干一件事，那他如何实现在同一时刻：即能监听键盘输入、又能监听其它人给你发的消息、同时还能把别人发的消息显示在屏幕上呢？你会说，操作系统不是有分时么？但是分时是指在不同进程间的分时， 即操作系统处理一会你的qq任务，又切换到word文档任务上了，每个cpu时间片分给你的qq程序时，事实上，你的qq还是同一时间只能干一件事情。&emsp;&emsp;再直白一点， 一个操作系统就像是一个工厂，工厂里面有很多个生产车间，不同的车间生产不同的产品，每个车间就相当于一个进程，且你的工厂又穷，供电不足，同一时间只能给一个车间供电，为了能让所有车间都能同时生产，你的工厂的电工只能给不同的车间分时供电，但是轮到你的qq车间时，发现只有一个干活的工人，结果生产效率极低，为了解决这个问题，就需要多加几个工人，让几个人工人并行工作，这每个工人，就是线程！ 进程和线程的区别 线程是共享内存空间的；进程的内存是独立的。 线程可以直接访问此进程中的数据部分；进程有他们独立拷贝自己父进程的数据部分，每个进程是独立的 同一进程的线程之间直接交流(直接交流涉及到数据共享，信息传递)；两个进程想通信，必须通过一个中间代理来实现。 创建一个新的线程很容易；创建新的进程需要对其父进程进行一次克隆。 一个线程可以控制和操作同一进程里的其他线程；但是进程只能操作子进程。 对主线程的修改，可能会影响到进程中其他线程的修改；对于一个父进程的修改不会影响其他子进程(只要不删除父进程即可)概念小结 线程是操作系统最小的调度单位，是一串指令的集合。 进程要操作CPU，必须先创建一个线程。 进程本身是不可以执行的，操作cpu是通过线程实现的，因为它是一堆执行，而进程是不具备执行概念的。就像一个屋子，屋子就是进程，但是屋子里面的每一个人就是线程，屋子就是内存空间。 单核CPU只能同时干一件事，但是为什么给我们的感觉是在干了很多件事？因为CPU太快了，可以有N多次切换。 进程是通过PID来区分的，并不是通过进程名来区分的。进程里面的第一个线程就是主线程，父线程和子线程是相互独立的，只是父线程创建了子线程，父线程down了，子线程不会受到影响的。 主线程修改会影响其他线程，因为它们是共享数据的。 线程启动比进程块，但是运行速度没有可比性 threading.Thread模块函数式多线程1234567891011121314151617import threading,time def run(n): print(&quot;run&quot;, n) time.sleep(2) print(n,&apos;end time:&apos;,time.time())&quot;&quot;&quot;第一个参数是线程函数变量，第二个参数args是一个元组变量参数，如果只传递一个值，就只需要i,如果需要传递多个参数，那么还可以继续传递下去其他的参数，其中的逗号不能少，少了逗号位置参数指引就会出错。&quot;&quot;&quot; t1 = threading.Thread(target=run, args=(&quot;t1&quot;,)) # 生成线程对象t2 = threading.Thread(target=run, args=(&quot;t2&quot;,))print(&apos;start:&apos;,time.time())t1.start() # start()函数启动一个线程t2.start() 继承式多线程1234567891011121314151617181920import threading,time class MyThread(threading.Thread): # 继承threading.Thread &quot;&quot;&quot;继承式多线程&quot;&quot;&quot; def __init__(self, n): super(MyThread,self).__init__() # 也可以写成这样threading.Thread.__init__(self) self.n = n def run(self): # 重写run方法 &quot;&quot;&quot;这个方法不能叫别的名字，只能叫run方法&quot;&quot;&quot; print(&quot;run&quot;, self.n) time.sleep(2) print(self.n,&apos;end time:&apos;,time.time()) t1 = MyThread(&quot;t1&quot;) # 实例化t2 = MyThread(&quot;t2&quot;)print(&apos;start:&apos;,time.time()) t1.start() # 启动一个多线程t2.start() &amp;emsp；&amp;emsp；在上面两个示例代码中，都包含一个主线程和两个子线程，主线程在启动子线程后，子线程就是独立的，所以主线程不会等待子线程的sleep就直接运行下去。如果实现等待线程执行结果可以使用join。 join函数12345678910111213141516171819202122import threading,time class MyThread(threading.Thread): # 继承threading.Thread &quot;&quot;&quot;继承式多线程&quot;&quot;&quot; def __init__(self, n): super(MyThread,self).__init__() # 也可以写成这样threading.Thread.__init__(self) self.n = n def run(self): # 重写run方法 &quot;&quot;&quot;这个方法不能叫别的名字，只能叫run方法&quot;&quot;&quot; print(&quot;run&quot;, self.n) time.sleep(2) print(self.n,&apos;end time:&apos;,time.time()) t1 = MyThread(&quot;t1&quot;) # 实例化t2 = MyThread(&quot;t2&quot;)print(&apos;start:&apos;,time.time()) t1.start() # 启动一个多线程t1.join()t2.start()print(&apos;main end time:&apos;,time.time()) 加了join之后，主线程依赖子线程执行完毕才往下走。 如果想要的是线程依然是并行效果，就需要更换join()的位置 计算多线程执行时间12345678910111213141516171819import threading,time def run(n): # 这边的run方法的名字是自行定义的，跟继承式多线程不一样，那个是强制的 print(&quot;task:&quot;, n) time.sleep(2) print(&quot;task done&quot;, n) start_time = time.time() # 开始时间t_obj = [] # 存放子线程实例for i in range(10): # 一次性启动10个线程 t = threading.Thread(target=run, args=(&quot;t-&#123;0&#125;&quot;.format(i),)) t.start() t_obj.append(t) # 为了不阻塞后面线程的启动，不在这里join，先放到一个列表中 for t in t_obj: # 循环线程实例列表，等待所有线程执行完毕 t.join() print(&quot;--------all thread has finished&quot;)print(&quot;cost:&quot;, time.time() - start_time) # 计算总耗时 守护进程&emsp;&emsp;只要主线程执行完毕，它不管子线程有没有执行完毕，就退出。现在就可以把所有的子线程变成守护线程。子线程变成守护线程之后，主程序就不会等子线程结束再退出了。说白了，设置一个主人，在设置几个仆人，这几个仆人都是为主人服务的。可以帮主人做很多事情，一个主人（主线程）可以有多个仆人（守护线程），服务的前提是，主线程必须存在，如果主线程不存在，则守护进程也没了。那守护进程是干嘛的呢？可以管理一些资源，打开一些文件，监听一些端口，监听一些资源，把一些垃圾资源回收，可以干很多事情，可以随便定义。123456789101112131415import threading,timedef run(n): print(&quot;task:&quot;, n) time.sleep(2) print(&quot;task done&quot;, n) start_time = time.time()for i in range(5): t = threading.Thread(target=run,args=(&quot;t-&#123;0&#125;&quot;.format(i),)) t.setDaemon(True) # Daemon意思是守护进程，这边是把当前线程设置为守护线程 t.start() print(&quot;--------all thread has finished&quot;)print(&quot;cost:&quot;, time.time() - start_time)守护进程一定要在start之前设置，start之后就不能设置了，之后设置会报错 使用场景&emsp;&emsp;比如写一个socket_server，每一个链接过来，socket_server就会给这个链接分配一个新的线程。如果我手动的把socket_server停掉。那这种情况你必须手动停掉服务，那它就要down了，这种情况下还要等线程结束吗？就不用等线程结束了，它自己就直接结束了。这样，是不是就可以把每个socket线程设置一个守护线程，主线程一旦down掉，就全部退出。 补充 theading.current_thead()查看当前线程； 用theading.active_count()来统计当前活动的线程数 线程个数=子线程数+主线程数 GIL锁(全局解释器锁)&emsp;&emsp;计算机有4核，代表着同一时间，可以干4个任务。如果单核cpu的话，我启动10个线程，我看上去也是并发的，因为是执行了上下文的切换，让看上去是并发的。但是单核永远肯定时串行的，它肯定是串行的，cpu真正执行的时候，因为一会执行1，一会执行2.。。。。正常的线程就是这个样子的。但是，在python中，无论有多少核，永远都是假象。无论是4核，8核，还是16核…….不好意思，同一时间执行的线程只有一个(线程)，它就是这个样子的。这个是python的一个开发时候，设计的一个缺陷，所以说python中的线程是假线程。 GIL存在的意义&emsp;&emsp;在新处理器上运行的程序要想充分利用其性能，必须按照并发方式进行重写。大部分开发者听到“并发”通常会立刻想到多线程的程序。目前来说，多线程执行还是利用多核系统最常用的方式。尽管多线程编程大大好于“顺序”编程，不过即便是仔细的程序员也没法在代码中将并发性做到最好。编程语言在这方面应该做的更好，大部分应用广泛的现代编程语言都会支持多线程编程。&emsp;&emsp;要想利用多核系统，Python必须支持多线程运行。作为解释型语言，Python的解释器必须做到既安全又高效。我们都知道多线程编程会遇到的问题。解释器要留意的是避免在不同的线程操作内部共享的数据。同时它还要保证在管理用户线程时保证总是有最大化的计算资源。&emsp;&emsp;那么，不同线程同时访问时，数据的保护机制是怎样的呢？答案是解释器全局锁。从名字上看能告诉我们很多东西，很显然，这是一个加在解释器上的全局（从解释器的角度看）锁（从互斥或者类似角度看）。这种方式当然很安全，但是它有一层隐含的意思（Python初学者需要了解这个）：对于任何Python程序，不管有多少的处理器，任何时候都总是只有一个线程在执行。 GIL锁关系图&emsp;&emsp;GIL(全局解释器锁)是加在python解释器里面的，效果如图：总结:&emsp;&emsp;需要明确的一点是GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。就好比C++是一套语言（语法）标准，但是可以用不同的编译器来编译成可执行代码。有名的编译器例如GCC，INTEL C++，Visual C++等。Python也一样，同样一段代码可以通过CPython，PyPy，Psyco等不同的Python执行环境来执行。像其中的JPython就没有GIL。然而因为CPython是大部分环境下默认的Python执行环境。所以在很多人的概念里CPython就是Python，也就想当然的把GIL归结为Python语言的缺陷。所以这里要先明确一点：GIL并不是Python的特性，Python完全可以不依赖于GIL。 CPython：是用C语言实现Pyhon，是目前应用最广泛的解释器。 线程锁（互斥锁）1234567891011121314151617181920212223import threading,time def run(n): global num # 把num变成全局变量 time.sleep(1) # 注意了sleep的时候是不占有cpu的，这个时候cpu直接把这个线程挂起了，此时cpu去干别的事情去了 num += 1 # 所有的线程都做+1操作 num = 0 # 初始化num为0t_obj = list()for i in range(100): t = threading.Thread(target=run, args=(&quot;t-&#123;0&#125;&quot;.format(i),)) t.start() t_obj.append(t) for t in t_obj: t.join() print(&quot;--------all thread has finished&quot;)print(&quot;num:&quot;, num) # 输出最后的num值#执行结果--------all thead has finished(&apos;num:&apos;, 97) #输出的结果 &emsp;&emsp;其实这种情况只能在python2.x 中才会出现的，python3.x里面没有这种现象，下面我们就用一张图来解释一下这个原因。如图：解释： 到第5步的时候，可能这个时候python正好切换了一次GIL(据说python2.7中，每100条指令会切换一次GIL),执行的时间到了，被要求释放GIL,这个时候thead 1的count=0并没有得到执行，而是挂起状态，count=0这个上下文关系被存到寄存器中. 然后到第6步，这个时候thead 2开始执行，然后就变成了count = 1,返回给count，这个时候count=1. 然后再回到thead 1，这个时候由于上下文关系，thead 1拿到的寄存器中的count = 0，经过计算，得到count = 1，经过第13步的操作就覆盖了原来的count = 1的值，所以这个时候count依然是count = 1，所以这个数据并没有保护起来。 添加线程锁&emsp;&emsp;通过上面的图我们知道，结果依然是不准确的。所以我还要加一把锁，这个是用户级别的锁。12345678910111213141516171819202122import threading,timedef run(n): lock.acquire() # 添加线程锁 global num # 把num变成全局变量 time.sleep(0.1) # 注意了sleep的时候是不占有cpu的，这个时候cpu直接把这个线程挂起了，此时cpu去干别的事情去了 num += 1 # 所有的线程都做+1操作 lock.release() # 释放线程锁 num = 0 # 初始化num为0lock = threading.Lock() # 生成线程锁实例t_obj = list()for i in range(10): t = threading.Thread(target=run, args=(&quot;t-&#123;0&#125;&quot;.format(i),)) t.start() t_obj.append(t) for t in t_obj: t.join() # 为join是等子线程执行的结果，如果不加，主线程执行完，下面就获取不到子线程num的值了，共享数据num值就错误了print(&quot;--------all thread has finished&quot;)print(&quot;num:&quot;, num) # 输出最后的num值小结： 用theading.Lock()创建一个lock的实例。 在线程启动之前通过lock.acquire()加加锁，在线程结束之后通过lock.release()释放锁。 这层锁是用户开的锁，就是我们用户程序的锁。跟我们这个GIL没有关系，但是它把这个数据相当于copy了两份，所以在这里加锁，以确保同一时间只有一个线程，真真正正的修改这个数据，所以这里的锁跟GIL没有关系，你理解就是自己的锁。 加锁，说明此时我来去修改这个数据，其他人都不能动。然后修改完了，要把这把锁释放。这样的话就把程序编程串行了。 死锁&emsp;&emsp;在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁，因为系统判断这部分资源都正在使用，所有这两个线程在无外力作用下将一直等待下去.（大锁内加小锁）1234567891011121314151617181920212223242526272829303132333435import threading,time mutexA=threading.Lock()mutexB=threading.Lock()class MyThread(threading.Thread): def run(self): self.func1() self.func2() def func1(self): print(&apos;%s func1 start&apos;%self.name) mutexA.acquire() print(&apos;%s func1 拿到A锁 &apos;%self.name) mutexB.acquire() print(&apos;%s func1 拿到B锁 &apos;%self.name) mutexB.release() mutexA.release() print(&apos;%s func1 end&apos;%self.name) def func2(self): print(&apos;%s func2 start&apos;%self.name) mutexB.acquire() print(&apos;%s func2 拿到B锁 &apos;%self.name) time.sleep(2) mutexA.acquire() print(&apos;%s func2 拿到A锁 &apos;%self.name) mutexA.release() mutexB.release() print(&apos;%s func2 end&apos;%self.name)if __name__ == &apos;__main__&apos;: for i in range(5): t=MyThread() t.start()线程1拿到B锁，线程3拿到A锁，造成同时等待，而且线程2、4、5也会因为拿不到锁等待。 递归锁（RLock）&emsp;&emsp;这个RLock内部维护着一个Lock和一个counter变量，counter记录了acquire的次数，从而使得资源可以被多次require。直到一个线程所有的acquire都被release，其他的线程才能获得资源。12345678910111213141516171819202122232425262728293031323334import threading,time mutexA=mutexB=threading.RLock()class MyThread(threading.Thread): def run(self): self.func1() self.func2() def func1(self): print(&apos;%s func1 start&apos;%self.name) mutexA.acquire() print(&apos;%s func1 拿到A锁 &apos;%self.name) mutexB.acquire() print(&apos;%s func1 拿到B锁 &apos;%self.name) mutexB.release() mutexA.release() print(&apos;%s func1 end&apos;%self.name) def func2(self): print(&apos;%s func2 start&apos;%self.name) mutexB.acquire() print(&apos;%s func2 拿到B锁 &apos;%self.name) time.sleep(2) mutexA.acquire() print(&apos;%s func2 拿到A锁 &apos;%self.name) mutexA.release() mutexB.release() print(&apos;%s func2 end&apos;%self.name)if __name__ == &apos;__main__&apos;: for i in range(5): t=MyThread() t.start()&emsp;&emsp;由于锁A，B是同一个递归锁，thread1拿到A,B锁，counter记录了acquire的次数2次，然后在func1执行完毕，就释放递归锁，在thread1释放完递归锁，执行完func1代码，接下来会有2种可能：1、thread1在次抢到递归锁，执行func2代码 2、其他的线程抢到递归锁，去执行func1的任务代码递归锁用于多重锁的情况，如果只是一层锁，就用不上递归锁递归锁原理其实很简单：就是每开一把门，在字典里面存一份数据，退出的时候去到door1或者door2里面找到这个钥匙退出，如图： 信号量（Semaphore）&emsp;&emsp;之前讲的线程锁（互斥锁）同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据 ，比如厕所有3个坑，那最多只允许3个人上厕所，后面的人只能等里面有人出来了才能再进去。 信号量是一个变量，控制着对公共资源或者临界区的访问。信号量维护着一个计数器，指定可同时访问资源或者进入临界区的线程数。 每次有一个线程获得信号量时，计数器-1。若计数器为0，其他线程就停止访问信号量，直到另一个线程释放信号量 1234567891011121314151617import threading,time def run(n): semaphore.acquire() # 加信号量锁 time.sleep(5) print(&quot;run the thread: %s\\n&quot; % n) semaphore.release() # 释放信号量锁 if __name__ == &apos;__main__&apos;: semaphore = threading.BoundedSemaphore(5) # 最多允许5个线程同时运行(Bounded:绑定，Semaphore：信号量) for i in range(20): t = threading.Thread(target=run, args=(i,)) t.start()while threading.active_count() != 1: passelse: print(&apos;----all threads done---&apos;) 上面程序的执行，会让人感觉是：分了4组，前5个同时完成，然后又5个同时进去。但是实际的效果是：这5个里面如果有3个完成，就会立刻再放3个进去。不会等5个都完成，每出来1个就放进去1个，出来几个放进去几个使用场景和总结 连接池，线程池，MySQL的有连接池，同一时间有多少个并发，就能连多少个连接。 我们为了保证我的socket_server，因为python不会默认现在你启动多少个线程，但是你启动的线程越多，就会把系统拉的越慢，就会把程序拉的越慢。这里就可以搞一个我同一时间放100线程个进来，就是用semaphore event&emsp;&emsp;事件处理的机制：全局定义了一个“Flag”，如果“Flag”值为 False，那么当程序执行 event.wait 方法时就会阻塞，如果“Flag”值为True，那么event.wait 方法时便不再阻塞。threading.Event 实现线程间通信,使用threading.Event可以使一个线程等待其他线程的通知 event = threading.Event() # 设置一个事件的全局变量 event.is_set() # 判断是否已经设置标志位。 event.wait() # 没有设置标志位的时候会阻塞，一遇到标志位就不会阻塞 #判断是否已经设置标志位。 event.set() # 设置标志位 ，标志位设置了，代表着绿灯，直接通行。 event.clear() # 清除标志位，标志位被清空，代表红灯，wait等待变绿灯。 1234567891011121314151617181920212223242526272829303132333435import threading,time event = threading.Event() # 生成线程事件实例 def lighter(): count = 0 event.set() # 先设置标志位,代表绿灯 while True: if count &gt; 5 and count &lt; 10: # 改成红灯 event.clear() # 清除标志位，变成红灯 print(&quot;red light is on ....&quot;) elif count &gt; 10: event.set() # 创建标志位，变成绿灯 count = 0 else: print(&quot;green light is on ....&quot;) time.sleep(1) count += 1 def car(name): while True: if event.is_set(): # 有标志位，代表是绿灯 print(&quot;&#123;0&#125; running ....&quot;.format(name)) time.sleep(1) else: # 如果不是绿灯就代表红灯 print(&quot;&#123;0&#125; sees red light ,waiting ....&quot;.format(name)) event.wait() # 阻塞 print(&quot;green light is on , start going ...&quot;) light = threading.Thread(target=lighter,) # 启动代表红绿灯的线程light.start()car1 = threading.Thread(target=car, args=(&quot;car1&quot;,)) # 启动代表车的线程car1.start()","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"使用vagrant搭建虚拟开发环境","date":"2018-09-10T13:51:45.000Z","path":"2018/09/10/使用vagrant搭建虚拟开发环境/","text":"虚拟机通过镜像文件创建虚拟环境: virtualbox VMware 什么是Vagrant&emsp;&emsp;Vagrant是构建在虚拟化技术之上的虚拟机运行环境管理工具,它的运行依赖于虚拟机： 建立和删除虚拟机配置虚拟机运行参数管理虚拟机运行状态自动化配置和安装开发环境打包分发虚拟机运行环境 优点&emsp;&emsp;跨平台、可移动、自动化部署无需人工干预 软件安装 virtualbox vagrant(注意vagrant和virtualbox之间的版本关系) xshell vagrant命令虚拟机的本质底层还是一个操作系统，使用虚拟机创建虚拟环境使用.iso文件，vagrant创建虚拟环境使用.box文件。 vagrant常用命令： 命令 描述 vagrant box list 查看目前已有的box vagrant box add 新增加一个box vagrant box remove 删除指定box vagrant init 初始化配置vagrantfile vagrant up 启动虚拟机 vagrant ssh ssh登录虚拟机 vagrant suspend 挂起虚拟机 vagrant reload 重启虚拟机 vagrant halt 关闭虚拟机 vagrant status 查看虚拟机状态 vagrant status 删除虚拟机 实际操作 虚拟机创建的创建和查看&emsp;&emsp;Vagrant使用基础镜像来快速克隆虚拟机，而不是从头开始构建虚拟机。这些基础镜像在 Vagrant 中被称为“box”，并且指定用于 Vagrant 环境的 box 始终是创建新 Vagrantfile 后的第一步。下载好.box文件后使用vagrant box add 虚拟环境名称 box文件名创建虚拟环境 新建imooc文件夹，进入文件夹，初始化配置vagrantfile，此时会生成一个vagrantfile文件 执行vagrant up，会在virtualbox中多一个虚拟环境实例，但是命令行一直会提示 这是由于虚拟机获取不到物理机的公钥, 创建Vagrantfile文件&emsp;&emsp;配置 Vagrant 项目的第一步是创建 Vagrantfile 文件。Vagrantfile 文件的目的有两个： 设置项目的根目录。Vagrant 中的许多配置选项是相对于这个根目录的。描述运行项目的机器类型和资源，以及需要安装的软件和访问方式。 &emsp;&emsp;Vagrant 内置了 vagrant init 命令，用于将目录初始化为 Vagrant 使用。请在你的终端中输入以下命令：123$ mkdir vagrant_getting_started$ cd vagrant_getting_started$ vagrant init &emsp;&emsp;命令执行完后会在你的目录中创建 Vagrantfile 文件。可以查看这个文件，里面写满了注释和示例。虽然看起来很吓人，但不要害怕，我们会尽快修改它。&emsp;&emsp;也可以在预先存在的目录中使用 vagrant init 命令配置已经存在的项目使用 Vagrant。&emsp;&emsp;如果你使用版本控制，则 Vagrantfile 可以用于项目的版本控制。这样，每个与该项目合作的人都可以从 Vagrant 中受益，而无需任何前期工作. box的安装与使用&emsp;&emsp;Vagrant 使用基础镜像来快速克隆虚拟机，而不是从头开始构建虚拟机。这些基础镜像在 Vagrant 中被称为“box”，并且指定用于 Vagrant 环境的 box 始终是创建新 Vagrantfile 后的第一步。 安装 box通过vagrant box add命令可以将 box 加入到 Vagrant。这会将 box 存储在一个特定的名称下，以便多个 Vagrant 环境可以重复利用。如果你还没有添加一个 box，可以这样做：1$ vagrant box add hashicorp/precise64 &emsp;&emsp;这将从 HashiCorp 的 Vagrant Cloud box 目录 下载名为“hashicorp/precise64”的 box。虽然从 HashiCorp 的 Vagrant Cloud下载 box 是最便利的方式，你也可以从本地文件或指定的 URL 等添加 box。&emsp;&emsp;对于当前用户，box 全局存储。每个项目都使用一个 box 作为初始镜像来克隆，并且从不修改基本镜像。这意味着如果你有两个项目都使用我们刚刚添加的 hashicorp/precise64 这个 box，则在一台 guest 机器中添加文件将不会对另一台机器产生影响。&emsp;&emsp;在上面的命令中，你会注意到这些 box 是有命名空间的。box 分为两部分 - 用户名和 box 名 - 用斜线分隔。在上面的例子中，用户名是“hashicorp”，并且 box 是“precise64”。也可以通过 URL 或本地文件路径来指定 box，但入门指南中不会涉及这些内容。 命名空间不保证规范 box！一个常见的误解是像“ubuntu”这样的命名空间代表了 Ubuntu 这个 box 的规范空间。这是不真实的。Vagrant Cloud上的命名空间的行为与 GitHub 上的命名空间非常相似。正如 GitHub 的支持团队无法协助解决某人存储库中的问题一样，HashiCorp 的支持团队无法管理第三方发布的 box。 使用 box&emsp;&emsp;现在 box 已经添加到了 Vagrant，需要配置项目使用这个 box 作为基准镜像。打开空白的 Vagrantfile 文件添加下面的内容：123Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;hashicorp/precise64&quot;end &emsp;&emsp;这个例子中的“hashicorp/precise64”必须要跟你在上面添加的 box 名字匹配。通过这个配置，Vagrant 知道需要使用哪个 box。如果之前没有添加 box，Vagrant 会在运行时自动下载并添加 box。&emsp;&emsp;可以通过 config.vm.box_version 来指定一个 box 的确切版本：1234Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;hashicorp/precise64&quot; config.vm.box_version = &quot;1.1.0&quot;end &emsp;&emsp;也可以直接使用 config.vm.box_url 指定一个 box 的 URL：1234Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;hashicorp/precise64&quot; config.vm.box_url = &quot;http://files.vagrantup.com/precise64.box&quot;end 在下一节中，我们将启动 Vagrant 环境并与其进行一点互动。 查找更多的 box&emsp;&emsp;对于本入门指南的其余部分，我们将仅使用之前添加的“hashicorp/precise64” box。但是在完成入门指南后，第一个问题可能就是“我在哪里可以找到更多的 box？”&emsp;&emsp;HashiCorp 的 Vagrant Cloud box 目录 是寻找更多 box 的最佳地点。HashiCorp 的 Vagrant Cloud 有一个可以通过各种平台和技术免费使用的公共目录。HashiCorp 的 Vagrant Cloud 也有很好的搜索功能，可以让你找到你关心的 box。&emsp;&emsp;除了寻找免费的 box，HashiCorp 的 Vagrant Cloud 允许你托管自己的 box，如果打算为自己的组织创建 box 的话还可以创建私有 box。 启动 vagrant 及 通过 ssh 登录虚拟机&emsp;&emsp;在终端运行 vagrant up 命令即可启动 Vagrant 环境：1$ vagrant up &emsp;&emsp;不到一分钟，命令就会执行完毕，运行 Ubuntu 的虚拟机会启动成功。Vagrant 运行虚拟机的时候没有 UI 界面。可以通过 SSH 连接到机器判断机器是否运行成功：1$ vagrant ssh &emsp;&emsp;这个命令会让你进入一个完整的 SSH 会话。会话建立后可以与机器进行交互，做任何你想做的事情。要小心 rm -rf /，因为 Vagrant 与包含 Vagrantfile 的主机上的目录共享一个 /vagrant 目录，这会删除所有这些文件。共享文件夹将在下一节介绍。&emsp;&emsp;花点时间思考刚刚发生的事情：通过终端中的一行配置和一条命令，我们创建了一个功能齐全的，可通过 SSH 访问的虚拟机。SSH 会话可以用 CTRL + D 终止。12vagrant@precise64:~$ logoutConnection to 127.0.0.1 closed. &emsp;&emsp;完成了需要使用虚拟机的工作后，在你的主机上运行 vagrant destroy，Vagrant 将终止虚拟机使用任何资源。&emsp;&emsp;vagrant destroy 命令实际上并不删除下载的 box 文件。可以使用vagrant box remove 命令彻底删除 box 文件。 同步目录（synced folders）&emsp;&emsp;尽管可以非常轻松的启动一台虚拟机，但很少有人希望通过 SSH 使用基于终端的编辑器来编辑文件。幸运的是，借助 Vagrant 你不需要这样做。通过使用同步目录，Vagrant 会自动同步 guest 机器上的文件。&emsp;&emsp;默认情况下，Vagrant 将你的项目的目录（即 Vagrantfile 的目录）共享到 guest 中的 /vagrant 目录。&emsp;&emsp;注意，当使用 vagrant ssh 目录进入机器时，默认进入 /home/vagrant 目录。 /home/vagrant 是与同步的 /vagrant 目录不同的目录。&emsp;&emsp;如果终端报错，提示不兼容 guest additions（或没有 guest additions），那么可能需要更新 box 或选择不同的 box，如 hashicorp/precise64。一些用户成功使用了 vagrant-vbguest 插件，但它并未得到 Vagrant 核心团队的正式支持。&emsp;&emsp;再次运行 vagrant up 启动 vagrant，然后通过 vagrant ssh 进入机器：123456$ vagrant up...$ vagrant ssh...vagrant@precise64:~$ ls /vagrantVagrantfile &emsp;&emsp;不管你信不信，你在虚拟机中看到的 Vagrantfile 文件实际上是你宿主机上的同一个文件。下面证明一下：1234vagrant@precise64:~$ touch /vagrant/foovagrant@precise64:~$ exit$ lsfoo Vagrantfile &emsp;&emsp;现在，“foo”文件会出现在你的宿主机上。你可以看到，Vagrant 保证了这个目录的同步。&emsp;&emsp;通过同步目录，你可以继续使用宿主机上你自己的编辑器，对宿主机中文件的改动会自动同步到 guest 机器中。 配置&emsp;&emsp;现在我们已经有了一个运行 Ubuntu 的虚拟机，并且可以在宿主机上编辑文件并自动同步到虚拟机。现在让我们安装一个 web 服务器，通过服务器访问这些文件。&emsp;&emsp;可以通过 SSH 进入并安装一个 web 服务器并开始工作，但每个使用 Vagrant 的人都必须这样做。相反，Vagrant 内置了对自动配置的支持。使用此功能时，Vagrant 将在执行 vagrant up 时自动安装软件，以便 guest 机器可以重复创建并可立即使用。 安装 Apache&emsp;&emsp;可以通过 shell 脚本来为刚才的项目设置 Apache。创建下面的 shell 脚本并命名为 bootstrap.sh，保存在 Vagrantfile 文件相同的目录下：12345678#!/usr/bin/env bashapt-get updateapt-get install -y apache2if ! [ -L /var/www ]; then rm -rf /var/www ln -fs /vagrant /var/wwwfi &emsp;&emsp;然后，配置 Vagrant 在设置机器的时候运行这个脚本。编辑 Vagrantfile 文件：1234Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;hashicorp/precise64&quot; config.vm.provision :shell, path: &quot;bootstrap.sh&quot;end &emsp;&emsp;“provision” 行是新添加的，告诉 Vagrant 使用 shell 命令执行 bootstrap.sh 文件来设置虚拟机。文件路径是相对于 Vagrantfile 文件所在的项目根目录的相对路径。 配置&emsp;&emsp;配置写完后，执行 vagrant up，Vagrant 会自动配置。可以在终端看到 shell 脚本的输出。如果虚拟机已经启动了，则需要执行 vagrant reload –provision，这会快速重启虚拟机并跳过初始化导入阶段。因为 Vagrant 只会在第一次 vagrant up 启动虚拟机的时候自动运行 provisioner，所以需要在 reload 命令中使用 provision 标志指示 Vagrant 必须运行 provisioner。&emsp;&emsp;Vagrant 运行结束后，web 服务器会成功运行。现在还不能在宿主机的浏览器上查看网页，但可以在通过 SSH 进入虚拟机后，通过加载文件来判断配置是否生效：123$ vagrant ssh...vagrant@precise64:~$ wget -qO- 127.0.0.1 &emsp;&emsp;上面例子会正常工作。我们安装 Apache 并设置其默认的 DocumentRoot 指向我们的 /vagrant 这个默认的同步目录。&emsp;&emsp;可以创建更多文件并在终端查看，下一步需要配置网络选项以便用宿主机的浏览器访问虚拟机。 对于复杂的配置脚本，将自定义的 Vagrant box 与预先安装的软件包打包在一起，而不是每次构建它们可能会更高效。入门指南未涵盖此主题，但可以在 自定义 box 文档中找到该主题。 网络&emsp;&emsp;现在，我们启动了 web 服务器，并且通过同步目录使用宿主机上的文件提供服务。然而，还只能通过虚拟机中的终端访问服务器。这一章节中，我们会使用 Vagrant 的网络特性，配置 Vagrant 以便从宿主机访问服务器。 端口转发（Port Forwarding）&emsp;&emsp;配置文件中支持端口转发选项。通过端口转发，可以在访问宿主机的某个端口时，自动将流量转发到虚拟机的指定端口。&emsp;&emsp;编辑 Vagrantfile 文件即可实现端口转发： 12345Vagrant.configure(&quot;2&quot;) do |config| config.vm.box = &quot;hashicorp/precise64&quot; config.vm.provision :shell, path: &quot;bootstrap.sh&quot; config.vm.network :forwarded_port, guest: 80, host: 4567end &emsp;&emsp;运行 vagrant reload 或 vagrant up（取决于虚拟机是否已经启动）加载配置。&emsp;&emsp;一旦虚拟机启动成功，在宿主机的浏览器中访问 http://127.0.0.1:4567。你应该看到虚拟机中的 web 服务器提供的网页。 其他网络Vagrant 还有其他网络配置选项，可以为虚拟机分配静态 IP 地址，或将虚拟机桥接到一个已经存在的网络上。更多资料参考这里。 share&emsp;&emsp;译者注：Vagrant Share 功能通过 ngrok 向所有人提供访问内网开发环境的能力。&emsp;&emsp;现在我们已经启动并运行了一台 Web 服务器，并且可以从你的机器访问，我们拥有一个相当实用的开发环境。但除了提供开发环境外，Vagrant 还可以轻松地在这些环境中共享和协作。Vagrant 中实现这个功能的特性叫做 Vagrant Share。&emsp;&emsp;Vagrant Share 使你可以通过网络向任何人共享 Vagrant 环境。这个功能会提供一个 URL 给你，任何人都可以通过这个 URL 路由到你的 Vagrant 环境。&emsp;&emsp;运行 vagrant share：12345$ vagrant share...==&gt; default: Creating Vagrant Share session...==&gt; default: HTTP URL: http://b1fb1f3f.ngrok.io... &emsp;&emsp;每个人的 URL 都是不同的。复制你的 URL，通过浏览器访问即可。&emsp;&emsp;如果你修改了共享目录中的文件，刷新 URL 后你会发现更新实时生效。这个 URL 直接路由到你的 Vagrant 环境，可以在世界上任意地点访问。&emsp;&emsp;在终端中通过 Ctrl + C 结束共享会话。可以再次刷新 URL 来验证开发环境是否仍在共享中。&emsp;&emsp;Vagrant Share 比简单的 HTTP 共享更加强大。详情参考 Vagrant Share 文档。 清理（teardown）&emsp;&emsp;我们现在有一个功能齐全的虚拟机，可以用于基本 Web 开发。但如果现在需要更换设备，或者在另一个项目上工作，如何清理我们的开发环境？&emsp;&emsp;借助 Vagrant，可以暂停（suspend），停止（halt）或销毁（destroy）虚拟机。每个选项都有优点和缺点。选择最适合的即可。 暂停（suspend）：通过调用 vagrant suspend 命令可以暂停虚拟机，此时会保存虚拟机当前运行状态并停止运行。当准备好再次工作时，运行 vagrant up 命令即可从上次暂停的状态恢复。这个方法的最大优点就是快，只要 5 到 10 秒就可以停止并开始工作。缺点是虚拟机仍占用磁盘空间，并且需要消耗更大的磁盘空间来保存虚拟机的 RAM 状态。 停止（halt）：通过调用 vagrant halt 命令可以优雅关闭虚拟机操作系统并断电。需要再次启动的时候，运行 vagrant up 命令即可。这个方法的好处是会干净地关闭你的机器，保存磁盘的内容，并让它再次干净地启动。缺点是冷启动需要较长时间，且虚拟机仍占用磁盘空间。 销毁（destroy）：通过调用 vagrant destroy 销毁虚拟机，这将从宿主机中删除虚拟机的所有痕迹。它会停止虚拟机，关闭它并删除其所有硬盘资源。当你准备好再次工作时，运行 vagrant up 命令即可。这样做的好处是，宿主机上不会留下残余物。虚拟机消耗的磁盘空间和 RAM 将被回收，并且主机保持清洁。缺点是，由于需要重新导入虚拟机并重新配置，因此需要更多时间。 https://app.vagrantup.com/boxes/search","tags":[{"name":"项目部署","slug":"项目部署","permalink":"http://yoursite.com/tags/项目部署/"}]},{"title":"django-扩展Django自带User模型，实现用户注册与登录","date":"2018-09-03T09:04:04.000Z","path":"2018/09/03/django-扩展Django自带User模型，实现用户注册与登录/","text":"&emsp;&emsp;用户的注册与登陆是一个网站应该具有的基本功能。前面的文章讲解了django自带的auth模块并使用第三方库完成登录注册等功能，今天来好好聊一聊如何扩展扩展Django自带User模型，并自己实现登录注册等功能。 扩展自带User模型&emsp;&emsp;我们需要实现用户登录注册功能就要先设计user表，如果django原有的user表不满足项目需求可以重新设计user表。 已有字段: id: 主键username 用户名，该字段不要随便改动password 密码email 邮箱first_name：名last_name：姓last_login Django自动记录用户最后登录时间is_superuser 表明用户是否是超级用户,默认是False(后台管理会用到)is_staff 表示是否是员工，默认是False(后台管理会用到)is_active 用户是否是激活状态，默认是Truedate_joined 注册时间，系统自动生成。 继承AbstractUser的方式 自定义user表12345678910111213141516171819from django.db import modelsfrom django.contrib.auth.models import AbstractUserclass UserProfile(AbstractUser): gender_choices = ( (&apos;male&apos;,&apos;男&apos;), (&apos;female&apos;,&apos;女&apos;) ) nick_name = models.CharField(&apos;昵称&apos;,max_length=50,default=&apos;&apos;) birthday = models.DateField(&apos;生日&apos;,null=True,blank=True) gender = models.CharField(&apos;性别&apos;,max_length=10,choices=gender_choices,default=&apos;female&apos;) adress = models.CharField(&apos;地址&apos;,max_length=100,default=&apos;&apos;) mobile = models.CharField(&apos;手机号&apos;,max_length=11,null=True,blank=True) image = models.ImageField(upload_to=&apos;image/%Y%m&apos;,default=&apos;image/default.png&apos;,max_length=100) class Meta: verbose_name = &apos;用户信息&apos; verbose_name_plural = verbose_name def __str__(self): return self.username 然后再setting.py中修改: AUTH_USER_MODEL = ‘users.UserProfile’ 执行makemigrations和migrate生成数据表: python manage.py makemigrationspython manage.py migrate 特别要注意图片和文件model需要指出上传地址upload_to image = models.ImageField(‘轮播图’,upload_to=’banner/%Y%m’,max_length=100)download = models.FileField(“资源文件”,upload_to=”course/resource/%Y/%m”,max_length=100) 图片上传需要安装第三方库 pip install pillow 使用1对1方式我们创建一个UserProfile模型，它只是对User模型的扩展, 与User是1对1的关系。1234567891011121314from django.db import modelsfrom django.contrib.auth.models import Userclass UserProfile(models.Model): # 与User是1对1关系 user = models.OneToOneField(User, on_delete=models.CASCADE, related_name=&apos;profile&apos;) org = models.CharField(&apos;Organization&apos;, max_length=128, blank=True) telephone = models.CharField(&apos;Telephone&apos;, max_length=50, blank=True) mod_date = models.DateTimeField(&apos;Last modified&apos;, auto_now=True) class Meta: verbose_name = &apos;User Profile&apos; def __str__(self): return self.user 然后你可以在终端输入以下命令，就可以创建UserProfile的数据表。12python manage.py makemigrations python manage.py migrate 登录注册功能的实现- 配置url url(r’^accounts/‘, include(‘users.urls’)), users.urls123456url(r&apos;^register/$&apos;, views.register, name=&apos;register&apos;),url(r&apos;^login/$&apos;, views.login, name=&apos;login&apos;),url(r&apos;^logout/$&apos;, views.logout, name=&apos;logout&apos;),url(r&apos;^user/(?P&lt;pk&gt;\\d+)/profile/$&apos;, views.profile, name=&apos;profile&apos;),url(r&apos;^user/(?P&lt;pk&gt;\\d+)/profile/update/$&apos;,views.profile_update,name=&apos;profile_update&apos;),url(r&apos;^user/(?P&lt;pk&gt;\\d+)/pwdchange/$&apos;, views.pwd_change,name=&apos;pwd_change&apos;),","tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"}]},{"title":"Docker入门","date":"2018-09-03T09:03:44.000Z","path":"2018/09/03/Docker入门/","text":"Docker概念&emsp;&emsp;Docker是开发人员和系统管理员使用容器进行开发，部署和运行应用程序的平台。使用Linux容器部署应用程序称为容器化。&emsp;&emsp;容器化越来越受欢迎，因为容器是： 灵活：即使是最复杂的应用也可以集装箱化。 轻量级：容器利用并共享主机内核。 可互换：您可以即时部署更新和升级。 便携式：您可以在本地构建，部署到云，并在任何地方运行。 可扩展：您可以增加并自动分发容器副本。 可堆叠：您可以垂直和即时堆叠服务。 图像和容器&emsp;&emsp;通过运行image启动容器。一个image是一个可执行的包，其中包括运行应用程序所需的所有代码，以及运行时的库，环境变量和配置文件。 容器和虚拟机&emsp;&emsp;容器在Linux上本机运行，与其他容器共享主机的内核。它运行一个独立的进程，不占用任何其他可执行文件的内存，使其轻量级。相比之下，虚拟机（VM）运行一个完整的“客户”操作系统，通过虚拟机管理程序对主机资源进行虚拟访问。通常，VM提供的环境比大多数应用程序需要的资源更多。 测试Docker版本&emsp;&emsp;运行docker –version并确保您拥有受支持的Docker版本：12docker --versionDocker version 17.12.0-ce, build c97c6d6 &emsp;&emsp;运行docker info或（docker version不–）查看有关docker安装的更多详细信息：12345678910docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.12.0-ceStorage Driver: overlay2... &emsp;&emsp;要避免权限错误（以及使用sudo），请将您的用户添加到docker组中。阅读更多。 测试Docker安装&emsp;&emsp;通过运行简单的Docker镜像hello-world来测试您的安装是否有效 ：1234567891011docker run hello-worldUnable to find image &apos;hello-world:latest&apos; locallylatest: Pulling from library/hello-worldca4f61b1923c: Pull completeDigest: sha256:ca0eeb6fb05351dfc8759c20733c91def84cb8007aa89a5bf606bc8b315b9fc7Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.... &emsp;&emsp;列出hello-world下载到您的计算机的图像：1docker image ls &emsp;&emsp;列出hello-world在显示其消息后退出的容器（由图像生成）。如果它仍在运行，您将不需要–all选项：1234docker container ls --allCONTAINER ID IMAGE COMMAND CREATED STATUS54f4984ed6a8 hello-world &quot;/hello&quot; 20 seconds ago Exited (0) 19 seconds ago Docker指令12345678910111213141516171819## List Docker CLI commandsdockerdocker container --help## Display Docker version and infodocker --versiondocker versiondocker info## Execute Docker imagedocker run hello-world## List Docker imagesdocker image ls## List Docker containers (running, all, all in quiet mode)docker container lsdocker container ls --alldocker container ls -aq 新的开发环境&emsp;&emsp;在过去，如果您要开始编写Python应用程序，那么首先需要在你的计算机上安装Python运行环境。而且该环境需要非常适合你的应用程序按预期运行，并且还需要与你的生产环境相匹配。&emsp;&emsp;如果使用Docker，你可以将可移植的Python运行环境时作为映像获取，无需安装。 然后，您的构建可以在应用程序代码旁边包含基本Python映像，确保您的应用程序，其依赖项和运行时都一起运行。&emsp;&emsp;这些可移植图像由称为Dockerfile的东西定义。 在win创建并运行一个容器 Dockerfile&emsp;&emsp;创建一个空目录。cd进入该目录，创建一个名为Dockerfile的文件，将以下内容复制并粘贴到该文件中，然后保存。Dockerfile命名必须为“Dockerfile”，Docker镜像构建时，会查找指定目录中的Dockerfile。 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] 应用程序本身&emsp;&emsp;再创建两个文件，requirements.txt和app.py requirements.txt12FlaskRedis app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket#Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \\ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \\ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) 构建应用程序&emsp;&emsp;我们准备构建应用程序。确保您仍处于新目录的顶层。这是ls应该显示的内容：12$ lsDockerfile app.py requirements.txt &emsp;&emsp;现在运行build命令。这会创建一个Docker镜像，我们将使用-t它来标记，因此它具有友好的名称。1docker build -t friendlyhello . &emsp;&emsp;你的构建的镜像将位于您机器的本地Docker镜像注册表中：123$ docker image lsREPOSITORY TAG IMAGE IDfriendlyhello latest 326387cea398 4.运行该应用程序&emsp;&emsp;运行应用程序，使用以下方法将计算机的端口4000映射到容器的已发布端口80 -p：1docker run -p 4000:80 friendlyhello &emsp;&emsp;浏览器打开http://localhost:4000 . 就可以访问hello world. 1. 如果使用win,请使用Docker Machine IP而不是localhost。例如，http：//192.168.99.100：4000。要查找IP地址，请使用该命令docker-machine ip。 2.如果在阿里云运行,需要访问IP:4000,注意要在安全组中添加规则 Dockerfile|Docker镜像|容器之间关系 Dockerfile：Dockerfile 是一个文本文件， 它是Docker镜像的描述文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。有了 Dockerfile，当我们需要定制自己额外的需求时，只需在 Dockerfile 上添加或者修改指令，重新生成 image 即可，省去了敲命令的麻烦。 Docker镜像： 通过Dockerfile做出来的，包含操作系统基础文件和软件运行环境，它使用分层的存储方式。 容器： 是运行起来的镜像，简单理解，Docker镜像相当于程序，容器相当于进程。使用 Dockerfile 定义镜像，依赖镜像来运行容器 &emsp;&emsp;Dockerfile 分为四部分：基础镜像信息、维护者信息、镜像操作指令、容器启动执行指令。一开始必须要指明所基于的镜像名称，接下来一般会说明维护者信息；后面则是镜像操作指令，例如 RUN 指令。每执行一条RUN 指令，镜像添加新的一层，并提交；最后是 CMD 指令，来指明运行容器时的操作命令。","tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"django-FBV&CBV","date":"2018-09-02T06:01:52.000Z","path":"2018/09/02/django-FBV&CBV/","text":"FBVFBV（function base views） 就是在视图里使用函数处理请求。1234567url(r&apos;^index/&apos;, views.index),def index(request): if request.method == &quot;GET&quot;: return HttpResponse(&quot;GET&quot;) elif request.method == &quot;POST&quot;: return HttpResponse(&quot;POST&quot;) step1：根据访问请求，在urls寻找匹配的url映射，得到views.indexsetp2：根据views.index ，调用views下index函数（传入参数request即用户请求信息）step3：根据客户请求信息对数据进行处理，通过HttpResponse返回客户端 CBVCBV（class base views） 就是在视图里使用类处理请求。12345678url(r&apos;^index/&apos;, views.Index.as_view()),from django.views import Viewclass Index(View): def get(self, request): return HttpResponse(&quot;GET&quot;) def post(self, request): return HttpResponse(&quot;POST&quot;) 如果是get或者post都执行的代码可以放到dispatch:123456def dispatch(self, request, *args, **kwargs): # 调用父类中的dispatch print(&apos;before&apos;) # 类似装饰器的功能 result = super(Home,self).dispatch(request, *args, **kwargs) print(&apos;after&apos;) # 类似装饰器的功能 return result 其实CBV过程可以看成是FBV过程的抽象化、对象化。他需要最基本的三个类View，ContextMixin，TemplateResponseMixin对应FBV的三个步骤： step1. View类提供类方法as_view(),用于调用dipatch()，根据request类型分发给get，post…等对应方法处理。step2. ContextMixin类，get_context_data(self, **kwargs)获取上下文数据，如果对数据库进行操作均可以继承该类，然后将增删改查的结果放入上下文数据中（即重写get_context_data）step3. TemplateResponseMixin类，将内容渲染到指定模板上，通过render_to_response()方法实现对应功能而其他模板视图基本就是在这三个类上进行继承重写后得到。","tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"}]},{"title":"django-编辑器Markdown的使用","date":"2018-09-01T14:46:43.000Z","path":"2018/09/01/django-编辑器Markdown的使用/","text":"&emsp;&emsp;之前的一篇博客写到了如何在django中使用Ueditor,今天我们看看如何在django中使用Markdown进行文本的编辑.它是基于editor.md插件 Markdown的安装Markdown使用的是源码安装的方式: 首先到github下载源码 把里面的markdown文件夹放到extra_apps中 然后在INSTALLED_APPS中添加markdown.并在url.py中添加: url(r’^markdown/‘, include(‘markdown.urls’)), 在setting.py中设置图片上传的文件夹 MARKDOWN_IMAGE_FLODER = ‘ markdown ‘ #图片会上传到media/markdown文件夹下 配置上传图片格式 MARKDOWN_IMAGE_FORMATS = [“jpg”，”jpeg”，”gif”，”png”，”bmp”，”webp”] 在admin中使用&emsp;&emsp;所有的TextField都使用markdown编辑器:12345678from django.db import modelsfrom markdown.widgets import AdminMarkdownWidgetclass TestAdmin(admin.ModelAdmin): formfield_overrides = &#123; models.TextField: &#123;&apos;widget&apos;: AdminMarkdownWidget()&#125;, &#125;admin.site.register(Test,TestAdmin) 在xadmin中使用12345678from django.db import modelsfrom markdown.widgets import XAdminMarkdownWidgetclass TestAdmin(admin.ModelAdmin): formfield_overrides = &#123; models.TextField: &#123;&apos;widget&apos;: XAdminMarkdownWidget()&#125;, &#125;xadmin.site.register(Test,TestAdmin) 在form中使用123456from django import formsfrom markdown.forms import MarkdownFieldclass BlogForm(forms.Form): name = forms.CharField() context = MarkdownField() 这里注意在前端需要添加去添加css和js1234567&lt;head&gt; &lt;title&gt;Hello Django!&lt;/title&gt; &#123;&#123;form.media&#125;&#125;&lt;/head&gt;&lt;body&gt;&#123;&#123;form&#125;&#125;&lt;/body&gt; 支持参数 widthheightthemepreviewThemeeditorThemesyncScrollingsaveHTMLToTextareaemojitaskListtocmtexflowChartsequenceDiagramcodeFold 123formfield_overrides = &#123; models.TextField: &#123;&apos;widget&apos;: AdminMarkdownWidget(emoji=False)&#125;, &#125; 最终后端效果 前端显示&emsp;&emsp;你会发现前端显示是有问题的,这个时候需要把markdown语法转换为html,我们需要安装django-markdown-deux. 首先运行 pip install django-markdown-deux 在INSTALLED_APPS中添加markdown_deux 在需要显示markdown的页面:12&#123;% load markdown_deux_tags %&#125;&#123;&#123; course.detail | markdown &#125;&#125; 最后效果: &emsp;&emsp;这里还有一个问题就是无法修改图片的大小,目前没有比较有效的解决办法,如果对图片大小要求比较高,可以使用七牛等支持参数的图床,如果有其他想法,欢迎交流~","tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"文本编辑","slug":"文本编辑","permalink":"http://yoursite.com/tags/文本编辑/"}]},{"title":"django-编辑器Ueditor的使用","date":"2018-09-01T14:46:26.000Z","path":"2018/09/01/django-编辑器Ueditor的使用/","text":"&emsp;&emsp;Ueditor是比较流行的富文本编辑器,主要用于内容的编辑、排版和图片上传等。本文主要介绍Ueditor的安装并搭配xadmin的使用。 富文本编辑器Ueditor&emsp;&emsp;UEditor是由百度web前端研发部开发所见即所得富文本web编辑器，具有轻量，可定制，注重用户体验等特点，开源基于MIT协议，允许自由使用和修改代码。 Ueditor的源码安装&emsp;&emsp;前往github下载源码然后解压，把DjangoUeditor文件夹拷贝到项目目录(extra_apps)下面。 setting和url中的配置 settings中添加app 123INSTALLED_APPS = [ &apos;DjangoUeditor&apos;,] MxOnline/urls.py 1path(&apos;ueditor/&apos;,include(&apos;DjangoUeditor.urls&apos; )), model和adminx中的配置 course/models.py中Course修改detail字段 1234class Course(models.Model): # detail = models.TextField(&quot;课程详情&quot;) detail = UEditorField(verbose_name=u&apos;课程详情&apos;, width=600, height=300, imagePath=&quot;courses/ueditor/&quot;, filePath=&quot;courses/ueditor/&quot;, default=&apos;&apos;) xadmin/plugs目录下新建ueditor.py文件,代码如下: 1234567891011121314151617181920212223242526272829303132import xadminfrom xadmin.views import BaseAdminPlugin, CreateAdminView, ModelFormAdminView, UpdateAdminViewfrom DjangoUeditor.models import UEditorFieldfrom DjangoUeditor.widgets import UEditorWidgetfrom django.conf import settingsclass XadminUEditorWidget(UEditorWidget): def __init__(self, **kwargs): self.ueditor_options = kwargs self.Media.js = None super(XadminUEditorWidget,self).__init__(kwargs)class UeditorPlugin(BaseAdminPlugin): def get_field_style(self, attrs, db_field, style, **kwargs): if style == &apos;ueditor&apos;: if isinstance(db_field, UEditorField): widget = db_field.formfield().widget param = &#123;&#125; param.update(widget.ueditor_settings) param.update(widget.attrs) return &#123;&apos;widget&apos;:XadminUEditorWidget(**param)&#125; return attrs def block_extrahead(self, context, nodes): js = &apos;&lt;script type=&quot;text/javascript&quot; src=&quot;%s&quot;&gt;&lt;/script&gt;&apos; %(settings.STATIC_URL + &quot;ueditor/ueditor.config.js&quot;) js += &apos;&lt;script type=&quot;text/javascript&quot; src=&quot;%s&quot;&gt;&lt;/script&gt;&apos; %(settings.STATIC_URL + &quot;ueditor/ueditor.all.min.js&quot;) nodes.append(js)xadmin.site.register_plugin(UeditorPlugin, UpdateAdminView)xadmin.site.register_plugin(UeditorPlugin, CreateAdminView) xadmin/plugs/init.py里面添加ueditor插件 123PLUGINS = ( &apos;ueditor&apos;,) course/adminx.py中使用: 123class CourseAdmin(object): #detail就是要显示为富文本的字段名 style_fields = &#123;&quot;detail&quot;: &quot;ueditor&quot;&#125; xadmin后台效果&emsp;&emsp;但是前段显示还是会有问题:&emsp;&emsp;这是因为需要在模板中必须关闭Django的自动转义才能正常显示:123&#123;% autoescape off %&#125;&#123;&#123; course.detail &#125;&#125;&#123;% endautoescape %&#125; 最终显示效果","tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"文本编辑","slug":"文本编辑","permalink":"http://yoursite.com/tags/文本编辑/"}]},{"title":"在线教育平台Mxonline-xadmin的使用","date":"2018-09-01T05:10:09.000Z","path":"2018/09/01/在线教育平台Mxonline-xadmin的使用/","text":"&emsp;&emsp;django自带了admin用于后台管理，但是在github上还有一个更好看、功能更强大的库来管理后台，叫xadmin，今天就来好好介绍一下xadmin的使用。 xadmin的安装&emsp;&emsp;通过文档我们可以发现，我们有两种方法可以进行安装。 使用pip install 安装 pip install django-xadmin 下载源码安装 需要安装requirements.txt中的依赖包 &emsp;&emsp;关于源码安装，首先到github搜索 xadmin下载源码，然后在项目的工程目录下新建一个extra_apps，把源码放在该目录下，注意extra_apps需要与apps一样在settings中设置。这里不在重复叙述了，然后手动安装requirements.txt中的依赖包。最后在INSTALLED_APPS中添加xadmin和crispy_forms。&emsp;&emsp;接下来配置url: from extra_apps import xadminurl(r’^xadmin/‘, xadmin.site.urls), &emsp;&emsp;然后执行migrations和migrate生成数据库表并创建superuser.就可以访问登录啦 注册app到xadmin后台 在app文件夹中新建adminx.py:123456789101112import xadminfrom .models import EmailVerifyRecord#xadmin中这里是继承object，不再是继承adminclass EmailVerifyRecordAdmin(object): # 显示的列 list_display = [&apos;code&apos;, &apos;email&apos;, &apos;send_type&apos;, &apos;send_time&apos;] # 搜索的字段，不要添加时间搜索 search_fields = [&apos;code&apos;, &apos;email&apos;, &apos;send_type&apos;] # 过滤 list_filter = [&apos;code&apos;, &apos;email&apos;, &apos;send_type&apos;, &apos;send_time&apos;]xadmin.site.register(EmailVerifyRecord,EmailVerifyRecordAdmin) xadmin的全局配置 全局配置,包括title和footer等 app名称汉化，菜单收叠。 使用Xadmin的主题功能。 全局配置12345678910from xadmin import viewsclass GlobalSettings(object): # 修改title site_title = &apos;Mxonline后台管理界面&apos; # 修改footer site_footer = &apos;在线教育平台&apos; # 收起菜单 menu_style = &apos;accordion&apos; #将title和footer信息进行注册xadmin.site.register(views.CommAdminView,GlobalSettings) 主题功能12345678from xadmin import views#创建xadmin的最基本管理器配置，并与view绑定class BaseSetting(object): # 开启主题功能 enable_themes = True use_bootswatch = True#将基本配置管理与view绑定xadmin.site.register(views.BaseAdminView,BaseSetting) 修改app的名字&emsp;&emsp;在后台左侧的app显示还是英文,如果要设置为中文需要在apps.py中添加verbose_name,然后在init.py中添加default_app_config.12345678apps.pyfrom django.apps import AppConfigclass UsersConfig(AppConfig): name = &apos;users&apos; verbose_name = &apos;用户&apos; __init__.pydefault_app_config = &apos;users.apps.UsersConfig&apos; 最终效果 后台用户用户权限&emsp;&emsp;超级用户拥有所有权限，其它添加的用户默认没有任何权限。进后台添加一个用户“Editor1”,勾上“职员状态”后，这个用户才可以登录进后台。&emsp;&emsp;默认没添加权限的用户登录到后台的情况如下：&emsp;&emsp;使用超级管理员账号登录后为用户Editor1添加查看章节的权限后：&emsp;&emsp;也可以添加一个组赋予相关权限，然后把用户添加到组中：&emsp;&emsp;重新登录Editor1查看权限：&emsp;&emsp;组里面的成员不但拥有自己本身的权限外，还会拥有组的权限 自定义icon&emsp;&emsp;xadmin的图标采用的是第三方css样式“font awesome”,我们可以进官网下载最新的样式替代原本的，下载地址&emsp;&emsp;下载完后把里面的“css”和“fonts”两个文件夹拷贝到xadmin的源码（路径：xadmin/static/vendor/font-awesome）里面 使用方法： 以course为例，进官网找到图标的样式 在course/adminx.py使用 12class CourseAdmin(object): model_icon = &apos;fa fa-book&apos; 后台内容设置默认排序、只读字段和不显示的字段123456789class CourseAdmin(object): &apos;&apos;&apos;课程&apos;&apos;&apos; list_display = [ &apos;name&apos;,&apos;desc&apos;,&apos;detail&apos;,&apos;degree&apos;,&apos;learn_times&apos;,&apos;students&apos;] #显示的字段 search_fields = [&apos;name&apos;, &apos;desc&apos;, &apos;detail&apos;, &apos;degree&apos;, &apos;students&apos;] #搜索 list_filter = [ &apos;name&apos;,&apos;desc&apos;,&apos;detail&apos;,&apos;degree&apos;,&apos;learn_times&apos;,&apos;students&apos;] #过滤 model_icon = &apos;fa fa-book&apos; #图标 ordering = [&apos;-click_nums&apos;] #排序 readonly_fields = [&apos;click_nums&apos;] #只读字段，不能编辑 exclude = [&apos;fav_nums&apos;] #不显示的字段 inlines添加数据&emsp;&emsp;model设计时章节信息和资源指向课程,但是按之前的配置方式章节信息和课程资源需要分开添加,我们可以用inlines去实现使用添加课程的时候添加章节和课程资源.123456789class LessonInline(object): model = Lesson extra = 0class CourseResourceInline(object): model = CourseResource extra = 0#在CourseAdmin中使用inlines添加上面两个的方法class CourseAdmin(object): inlines = [LessonInline,CourseResourceInline] #增加章节和课程资源 &emsp;&emsp;可以看到在添加课程页面就可以直接添加与之关联的章节信息和资源的内容. 一张表分两个Model来管理比如课程里面分为轮播课程和不是轮播课程两种类型，它们是存储在同一张表,但是我们可以分开来管理.1234567class BannerCourse(Course): &apos;&apos;&apos;显示轮播课程&apos;&apos;&apos; class Meta: verbose_name = &apos;轮播课程&apos; verbose_name_plural = verbose_name #这里必须设置proxy=True，这样就不会再生成一张表，同时还具有Model的功能 proxy = True #一种继承的方式 1234567普通课程和轮播课程的后台管理通过添加该函数来进行筛选.def queryset(self): # 重载queryset方法，来过滤出我们想要的数据的 qs = super(CourseAdmin, self).queryset() # 只显示is_banner=True的课程 qs = qs.filter(is_banner=False) return qs 其他常用功能 list_editable : 在列表页可以直接编辑的 12class CourseAdmin(object): list_editable = [&apos;degree&apos;,&apos;desc&apos;] 自定义函数作为列显示 12345678910model.pyclass Course(models.Model):def get_zj_nums(self): #获取课程的章节数 return self.lesson_set.all().count()get_zj_nums.short_description = &apos;章节数&apos; #在后台显示的名称adminx.pyclass CourseAdmin(object): list_display = [&apos;get_zj_nums&apos;] #直接使用函数名作为字段显示 显示自定义的html代码 1234567891011model.pyclass Course(models.Model):def go_to(self): from django.utils.safestring import mark_safe #mark_safe后就不会转义 return mark_safe(&quot;&lt;a href=&apos;https://home.cnblogs.com/u/derek1184405959/&apos;&gt;跳转&lt;/a&gt;&quot;)go_to.short_description = &quot;跳转&quot;adminx.pyclass CourseAdmin(object): list_display = [&apos;go_to&apos;] refresh定时刷新工具 12class CourseAdmin(object): refresh_times = [3,5] #自动刷新（里面是秒数） 字段联动 1234567891011121314class CourseAdmin(object): def save_models(self): # 在保存课程的时候统计课程机构的课程数 # obj实际是一个course对象 obj = self.new_obj # 如果这里不保存，新增课程，统计的课程数会少一个 obj.save() # 确定课程的课程机构存在。 if obj.course_org is not None: #找到添加的课程的课程机构 course_org = obj.course_org #课程机构的课程数量等于添加课程后的数量 course_org.course_nums = Course.objects.filter(course_org=course_org).count() course_org.save()","tags":[{"name":"django项目","slug":"django项目","permalink":"http://yoursite.com/tags/django项目/"},{"name":"Mxonline","slug":"Mxonline","permalink":"http://yoursite.com/tags/Mxonline/"},{"name":"xadmin","slug":"xadmin","permalink":"http://yoursite.com/tags/xadmin/"}]},{"title":"在线教育平台Mxonline-django基本设置和model设计","date":"2018-09-01T05:09:09.000Z","path":"2018/09/01/在线教育平台Mxonline-django基本设置和model设计/","text":"&emsp;&emsp;在学习了一段时间的django框架后，也做了几个较为完整的项目，现将整个的过程做个记录和整理，也算是进行一次章节和回顾吧。接下来几天将从项目工程创建到linux服务器部署中较为关键的点进行记录和总结。 开发环境和开发平台 win10 Pycharm python3.6.2 django1.11.6 虚拟环境的安装与使用 virtualenv的安装：在win下使用pip install virtualenv执行安装,安装成功后使用pip list可以查看到版本信息 在需要创建虚拟环境的目录下执行virtualenv testvir就可以创建一个虚拟环境. cd 进入虚拟环境目录,通过dir查看该目录下文件,cd Scripts,执行activate可以激活虚拟环境,执行deactivate.bat可以退出虚拟环境 virtualenvwrapper可以进行虚拟环境的管理 win下安装pip install virtualenvwrapper-win,安装成功后使用mkvirtualenv testEve创建虚拟环境,会提示创建的虚拟环境的位置 使用workon查看已经安装的虚拟环境,使用workon testEve,如果虚拟环境已经激活,在任何时候执行deactivate.bat就可以退出虚拟环境 新工程设置&emsp;&emsp;工程目录下创建log(日志)、media(上传文件)、templates(模板文件)、static(静态文件)，并新建setting_dev.py用于存储密码等信息，如果将项目托管于github可以把该文件放到.gitignore.&emsp;&emsp;在工程目录下新建apps用于存放所有app,此时导入需要from apps.app1 import views,可以apps右键Mark Directory As - Sources Root(全局搜索路径),然后就可以通过from app1 import views,但是Mark后Pycharm能识别,但是使用命令行无法识别,需要再在setting中添加: sys.path.inser(0,os.path.join(BASE_DIR,’apps’)) 其他配置： 数据库切换成mysql,安装mysqlclient连接myql,同时在setting_dev.py中配置数据库12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;mxonline&apos;, #数据库名字 &apos;USER&apos;: &apos;root&apos;, #账号 &apos;PASSWORD&apos;: &apos;123456&apos;, #密码 &apos;HOST&apos;: &apos;127.0.0.1&apos;, #IP &apos;PORT&apos;: &apos;3306&apos;, #端口 &#125;&#125; 在setting.py配置上传文件和静态文件的路径:123456STATIC_URL = &apos;/static/&apos;STATICFILES_DIRS = ( os.path.join(BASE_DIR,&apos;static&apos;),)MEDIA_URL = &apos;/media/&apos;MEDIA_ROOT = os.path.join(BASE_DIR,&apos;media&apos;) 在url中配置处理图片的视图函数1234from django.conf.urls.static import staticfrom django.conf import settingsif settings.DEBUG: urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 修改语言和时区12345LANGUAGE_CODE = &apos;zh_hans&apos;TIME_ZONE = &apos;Asia/Shanghai&apos;USE_I18N = TrueUSE_L10N = TrueUSE_TZ = False &emsp;&emsp;根据项目要求,会有一个users、course、organization的app,同时针对用户的各种操作设计operation的app python manage.py startapp userspython manage.py startapp coursepython manage.py startapp organizationpython manage.py startapp operation model设计&emsp;&emsp;在model设计之前一定要梳理每一个model需要哪些字段,这是一个项目的关键.","tags":[{"name":"django项目","slug":"django项目","permalink":"http://yoursite.com/tags/django项目/"},{"name":"Mxonline","slug":"Mxonline","permalink":"http://yoursite.com/tags/Mxonline/"}]},{"title":"常用Markdown语法说明","date":"2018-08-30T13:10:19.000Z","path":"2018/08/30/常用Markdown语法说明/","text":"Markdown 是一种轻量级标记语言，它允许人们“使用易读易写的纯文本格式”编写文档，本文主要针对Hexo中Markdown常用的语法进行总结，更详细的内容请参考Hexo官方书写格式链接和Markdown书写格式链接 标题Markdown支持两种标题的语法，Setext和atx形式：Setext形式是用底线的形式，利用 = (最高阶标题)和 - (第二阶标题)。Atx形式在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶。 最高阶标题第二阶标题H1标题H2标题H3标题H4标题H5标题H6标题区块引用区块引用则使用 email 形式的 ‘&gt;’ 角括号。 区块引用 嵌套引用 修辞和强调强调内容两侧分别加上星号或者底线。斜体粗体删除 表格 至少一个- 使用:来设置对其方式 第一列 第二列 第三列 内容 内容 内容 列表无序列表使用星号、加号或减号来做为列表。 一号 二号 三号 四号 五号 六号 有序列表 一号 二号 链接这是我的博客地址 分割线 图片图片的语法和链接很像，只需在链接的基础上前方加一个！注意图片大小的设置方式,关于其他设置可以参考七牛云 代码main.c12345int i = 0; i = 1; for (int i = 0; i &lt; 100; i++)&#123; printf(\"hello markdown!\\n\");&#125; 任务列表 选项一 选项二 选项三","tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://yoursite.com/tags/Markdown/"}]},{"title":"linux-Linux基础知识","date":"2018-08-11T04:03:44.000Z","path":"2018/08/11/linux-Linux基础知识/","text":"&emsp;&emsp;作为一个程序猿，基本都会接触 linux , 所以一些基本的操作和指令还是要掌握的， 这里整理出平时使用 linux 常用的一些指令。linux命令大全：传送门 Linux系统目录结构 目录 解释 备注 bin 存放常用可执行文件或者链接文件 (绿色或浅蓝色)ls,cat,mkdir等常用命令一般都在这里 etc 存放系统管理所需要的配置文件和子目录 home 用户的主目录 在Linux中，每个用户都有一个自己的目录,用户创建时会在该目录下创建一个目录,目录名是以用户的账号命名 root 该目录为系统管理员，也称作超级权限者的用户主目录 root的家目录 tmp 存放一些临时文件 boot Linux时使用的一些核心文件 存储系统启动文件 dev Linux的硬件设备目录 linux系统所有的硬件都是通过文件表示 lib 系统最基本的动态连接共享库 media linux系统会自动识别一些设备 例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下 mnt 用户临时挂载别的文件系统,，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容 sbin s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序 该目录文件对应指令都是root用户可以执行的 usr 用户的很多应用程序和文件都放在这个目录下,类似于windows下的program files目录 该目录经常用于安装各种软件 var 这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件 /var：这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在/var/log 目录下 /bin,/sbin,/usr/sbin,/usr/bin目录 使用权限 /bin下的命令管理员和一般的用户都可以使用 /sbin下的命令通常只有管理员才可以运行。 命令功能 /sbin 下的命令属于基本的系统命令，如shutdown，reboot，用于启动系统，修复系统 /bin下存放一些普通的基本命令，如ls,chmod等，这些命令在Linux系统里的配置文件脚本里经常用到。 /usr/sbin,/usr/bin存放一些系统非必须的命令 /usr/bin 是你在后期安装的一些软件的运行脚本。主要放置一些应用软体工具的必备执行档 /usr/sbin 放置一些用户安装的系统管理的必备程式 参考文章：传送门 &emsp;&emsp;如果新装的系统，运行一些很正常的诸如：shutdown，fdisk的命令时，悍然提示：bash:command not found。那么首先就要考虑root 的$PATH里是否已经包含了这些环境变量。 目录与文件 功能 命令 备注 白色 普通文件 蓝色 文件夹 [d] 浅蓝色 链接文件 [l] 红色 压缩文件 [-] 红色闪烁 链接文件有问题 绿色 可执行文件 黄色 设备文件 灰色 其他文件 进入一个目录 cd xxx 列出当前目录文件列表 ls -al -l：长格式显示-a：全部的文件 返回上一目录 cd .. 返回根目录 cd / 显示当前目录路径 pwd 返回上一次所在目录 cd - 创建目录 mkdir xx 创建文件 touch xx 复制 cp [选项] 原文件 目标路径 -r：递归，复制目录时必须有此选项-p：保持原文件的权限、修改时间等属性不变 移动 mv [选项] 原文件 目标路径 删除 rm [选项] 文件或目录 -r：递归删除（含目录）-f：强制删除 删除空的目录 rmdir xxx 由第一行开始显示文件内容 cat xxx 显示最后一屏内容 从最后一行开始显示文件内容 tac xxx 显示的时候，同时输出行号 nl xxx 一页一页的显示文件内容(不支持回看) more Space：代表向下翻一页b：往回翻页Enter：向下翻一行/xx：向下搜索xxq：立刻离开 more 一页一页的显示文件内容(支持回看) less Space或PgDn：代表向下翻一页PgUp：往回翻页/xx：向下搜索xx?xx：向前搜索xxq：立刻离开 more 取出文件前面几行 head -n 文件名 -n ：后面接数字，代表显示几行 取出文件后面几行 tail -n 文件名 -n ：后面接数字，代表显示几行 读写执行 rwx r:读[4]w:写[2]x:执行[1]-:没有权限[0] 更改文件所属用户组 chgrp [-R] 属组名 文件名 更改文件所属用户和所属用户组 chown [–R] 属主名 文件名chown [-R] 属主名：属组名 文件名 更改文件9个属性 chmod [-R] 777 文件名 -R : 进行递归(recursive)的持续变更 目录对权限的使用 读：是否可以查看该目录内部的文件信息 写：是否可以给该目录创建、删除文件 执行：指定用户是否可以cd进入该目录 用户和用户组管理 功能 命令 备注 添加新的用户账号 useradd [选项] 用户名 会在home文件夹下创建一个名字为用户名的文件夹 删除用户账号 userdel [选项] 用户名 修改用户账号 usermod [选项] 用户名 修改用户密码 passwd [选项] 用户名 用户账号刚创建时没有口令，但是被系统锁定，必须设置口令后才能使用 增加一个新的用户组 groupadd [选项] 用户组 删除用户组 groupdel 用户组 修改用户组的属性 groupmod [选项] 用户组 &emsp;&emsp;不同的用户在不同的组,所以对不同的文件有不同的操作权限,root只需要关心用户属于哪个组/etc/passwd存储的用户信息: 磁盘管理 功能 命令 备注 查看文件系统的整体磁盘使用量 df [选项] 目录或文件名 -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示 查看文件和目录磁盘使用的空间 du [选项] 目录或文件名 磁盘分区操作 fdisk fdisk -l，系统将会把整个系统内能够搜寻到的装置的分区均列出来 vim命令 功能 命令 备注 移动到这个档案的第一行 gg 移动到这个档案的最后一行 G 光标移到该行最前面 0或[home] 光标移到该行最后面 $或[End] 屏幕向下移动一页 [Ctrl] + [f]或[Page Down] 屏幕向上移动一页 [Ctrl] + [b]或[Page Up] 向光标之下寻找一个名称为 word 的字符串 /word 向光标之上寻找一个字符串名称为 word 的字符串 ?word 重复前一个搜寻的动作 n 反向进行前一个搜寻动作 N 删除游标所在的那一整行 dd 复制游标所在的那一整行 yy 使用word2替换word1 :%s/word1/word2/g /gc表示需要确认 后退(撤销) u 前进(重新执行) [Ctrl]+r 重复前一个动作 . 进入输入模式 i 将编辑的数据写入硬盘档案中 w w!为强制写入 离开 q q!为强制离开 储存后离开 :wq wq! 则为强制储存后离开 压缩文件 功能 命令 备注 打包并压缩文件 tar -zcvf test.tar.gz ./test/ 打包后，以 gzip 压缩 解压 tar -zxvf test.tar.gz 其他常用操作查看各个命令的使用文档 man cp 查找 find /home -name “*.txt” 在/home目录下查找以.txt结尾的文件名，如果没有指定目录会在当前目录和子目录下查找（硬盘）which ls 定位/返回ls所在的路径(查找可执行文件) 软件操作命令 软件管理包：yum 安装软件：yum install xxx 卸载软件：yum remove xxx 搜索软件：yum search xxx 清理缓存：yum clean packages 列出已按照：yum list 软件包信息：yum info xxx (yum info vim-commo) 服务器硬件资源和磁盘操作 内存：free -m 硬盘：df -h 负载：w/top cpu个数和核数：cat /proc/cpuinfo log查看 日志以文本可以存储在“/var/log/”目录下后缀名为.log 查看所有进程 ps aux | ps -ef 查看所有进程ps -ef | grep java 查看所有进程里 CMD 是 java 的进程信息 ps aux 是用BSD的格式来显示 java这个进程 显示的项目有：USER , PID , %CPU , %MEM , VSZ , RSS , TTY , STAT , START , TIME , COMMANDps -ef 是用标准的格式显示java这个进程 显示的项目有：UID , PID , PPID , C , STIME , TTY , TIME , CMD UID //用户ID、但输出的是用户名PID //进程的IDPPID //父进程IDC //进程占用CPU的百分比STIME //进程启动到现在的时间TTY //该进程在那个终端上运行，若与终端无关，则显示? 若为 pts/0等，则表示由网络连接主机进程。CMD //命令的名称和参数 kill 命令用于终止进程 kill -9 [PID] -9 表示强迫进程立即停止 通常用 ps 查看进程 PID ，用 kill 命令终止进程 Linux 查看某个服务的端口 netstat -anp | grep ssh 查看以开放哪些端口 netstat -nupl (UDP类型的端口)netstat -ntpl (TCP类型的端口) 端口不是独立存在的，它是依附于进程的。某个进程开启，那么它对应的端口就开启了，进程关闭，则该端口也就关闭了。下次若某个进程再次开启，则相应的端口也再次开启。而不要纯粹的理解为关闭掉某个端口，不过可以禁用某个端口。 关掉对应的应用程序，则端口就自然关闭了 linux 中 find 和 grep 的区别 Linux 系统中 grep 命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 find 命令从指定的起始目录开始，递归地搜索其各个子目录，查找满足寻找条件的文件并对之采取相关的操作。 grep 是查找匹配条件的行，find 是搜索匹配条件的文件 管道pipe变量修饰器/管道：前者的输出是后者的输入参数。 ls -l | wc //计算当前目录一共有多少个文件 ls -l | head -10 //以详细列表形式查看当前目录下前10个文件 查看ip ifconfig ip addr 替换默认源 1、备份系统源cd /etc/yum.repos.dmv CentOS-Base.repo CentOS-Base.repo.bak 2、设置默认源为163(注意linux版本为7.3) wget https://mirrors.163.com/.help/CentOS7-Base-163.repomv CentOS7-Base-163.repo CentOS-Base.repo 3、执行yum源更新 yum clean all // 清除以前的缓存yum makecache // 重建缓存yum update //源的服务器更新了之后旧的包可能被新的替代了，所以需要yum update或者yum upgrade 切换用户 su admin 输入密码传送门 Linux链接概念&emsp;&emsp;Linux 链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln 命令产生硬链接。 硬连接&emsp;&emsp;硬连接指通过索引节点来进行连接。在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在 Linux 中，多个文件名指向同一索引节点是存在的。比如：A 是 B 的硬链接（A 和 B 都是文件名），则 A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，两个文件名指向同一个文件，A 和 B 对文件系统来说是完全平等的。删除其中任何一个都不会影响另外一个的访问。&emsp;&emsp;硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。 软连接&emsp;&emsp;另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于 Windows 的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。比如：A 是 B 的软链接（A 和 B 都是文件名），A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号不相同，A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）。A 和 B 之间是“主从”关系，如果 B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。&emsp;&emsp;硬连接文件 f2 与原文件 f1 的 inode 节点相同，均为 9797648，然而符号连接文件的 inode 节点不同。&emsp;&emsp;当删除原始文件 f1 后，硬连接 f2 不受影响，但是符号连接 f1 文件无效 总结 1.删除符号连接f3,对f1,f2无影响； 2.删除硬连接f2，对f1,f3也无影响； 3.删除原文件f1，对硬连接f2没有影响，导致符号连接f3失效； 4.同时删除原文件f1,硬连接f2，整个文件会真正的被删除。 软链接link 就是win的快捷方式: ln -s 源文件 软链接 源文件 被删除，对应的软链接就变为”无效链接”，如果再创建一个同名源文件，软链接又恢复为有效链接文件。硬链接 ln [-d] 源文件 硬链接 系统里边文件的名称(引用)就是硬链接,一个文件可以有多个名字，它们都是同一个文件实体的硬链接 同一个文件实体可以创建多个文件名字，他们都是”硬链接”，好处是即使删除其中的一个名字，也可以保证文件实体被垃圾回收机制给收走。 只有普通文件可以设置硬链接，目录不可以 同一个源文件的所有硬链接文件必须 在同一个硬盘、同一个分区里边 当 rm 一个文件的时候，那么此文件的硬链接数减1，当硬链接数为 0 的时候，文件被删除。 操作系统分区原理win系统分区原理 linux系统分区原理 ssh原理https://www.jianshu.com/p/33461b619d53","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]}]